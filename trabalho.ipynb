{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prjeto 2\n",
    "dependecies:\n",
    "pip install\n",
    ">Tkinter\n",
    ">\n",
    ">pyTorch\n",
    ">\n",
    ">tqdm\n",
    ">\n",
    ">ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Interface\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "import time\n",
    "#Comunication\n",
    "import socket\n",
    "import re\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### necessary values for tkinter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values necessary to construct interface\n",
    "canva_size=700\n",
    "color1='black'\n",
    "color2='white'\n",
    "default=0\n",
    "#grid_size=args['size'] deixou de ser preciso, pois ou é 4 ou 6 dependento do size do ataxx \n",
    "go_offset=45\n",
    "EAST=[1,0]\n",
    "SOUTH=[0,1]\n",
    "WEST=[-1,0]\n",
    "NORTH=[0,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configurações do jogo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  __HERE_YOU_CAN_EDIT_YOU_GAME_PERFERENCES__\n",
    "#  *   Scroll EVERYTHING DOWN TO EDIT   *\n",
    "#  PLEASE, EDIT ONLY WHERE IS MARKED WITH:  #&_EDIT_HERE_&#\n",
    "\n",
    "comunication = {\n",
    "    'on': True,             #if comunication is on, , run server.py first and then the mains\n",
    "    'off': False,\n",
    "    'port': 12401,\n",
    "    'server_host':'localhost',\n",
    "    'client_host':'localhost',\n",
    "}\n",
    "\n",
    "#ATAXX\n",
    "# IF you want to add non playable blocks, use number 3\n",
    "board4 = {\n",
    "    'size': 4,\n",
    "    'board': np.array([[1, 0, 0, -1],          #&_EDIT_HERE_&# -> edit initial state as you wish \n",
    "                        [0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0],\n",
    "                        [-1, 0, 0, 1]])\n",
    "}\n",
    "board5 = {\n",
    "    'size': 5,\n",
    "    'board': np.array([[1, 0, 0, 0, -1],    #&_EDIT_HERE_&# -> edit initial state as you wish\n",
    "                        [0, 0, 0, 0, 0],\n",
    "                        [0, 0, 3, 0, 0],\n",
    "                        [0, 0, 0, 0, 0],\n",
    "                        [-1, 0, 0, 0, 1]])\n",
    "}\n",
    "board6 = {\n",
    "    'size': 6,\n",
    "    'board': np.array([[1, 0, 0, 0, 0, -1],    #&_EDIT_HERE_&# -> edit initial state as you wish\n",
    "                        [0, 0, 0, 0, 0, 0],\n",
    "                        [0, 0, 0, 3, 0, 0],\n",
    "                        [0, 0, 3, 0, 0, 0],\n",
    "                        [0, 0, 0, 0, 0, 0],\n",
    "                        [-1, 0, 0, 0, 0, 1]])\n",
    "}\n",
    "\n",
    "#GO\n",
    "board7 = {\n",
    "    'size': 7,\n",
    "    'board': np.array([[0, 0, 0, 0, 0, 0, 0],    #&_EDIT_HERE_&# -> edit initial state as you wish\n",
    "                        [0, 0, 0, 0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0, 0, 0, 0]])\n",
    "}\n",
    "\n",
    "board9 = {\n",
    "    'size': 9,\n",
    "    'board': np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0],    #&_EDIT_HERE_&# -> edit initial state as you wish\n",
    "                        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        [0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "}\n",
    "\n",
    "\n",
    "game_mode = {\n",
    "    'agent_vs_agent': 3,\n",
    "    'agent_vs_human': 2,\n",
    "    'human_vs_human': 1,\n",
    "}\n",
    "\n",
    "jogar = {\n",
    "    'Ataxx': 'A',\n",
    "    'Go': 'G'\n",
    "}\n",
    "\n",
    "#GAME_PREFERENCES      <edit_here>                         #&_EDIT_HERE_&# :\n",
    "configurations = {\n",
    "    #with comunication, edit below:\n",
    "    'server_game': \"G7x7\",                                  #\"A6x6\" \"A4x4\" \"G7x7\" \"G9x9\"\n",
    "    'comunication': comunication['off'],                    #'off'/'on'. -> if 'off' edit below: \n",
    "    #without comunication, set it off and edit below:\n",
    "    'size': 7,                                              #4/6 -> ataxx\n",
    "    'game_mode': game_mode['agent_vs_human'],               #['agent_vs_agent']/['agent_vs_human']/['human_vs_human'],\n",
    "    #common to both:\n",
    "    'time_between_moves': 10,                             #time_between_moves without comunication in miliseconds\n",
    "    'jogo': jogar['Go']                                  #[Ataxx]/[Go], por enquanto só ataxx\n",
    "}\n",
    "\n",
    "#...check update..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Ataxx and Go are built in a way so that the state, player and verification features are external to the class in order to be shared in comunication, montecarlo different braches and interface.\n",
    "\n",
    "Both Ataxx and Go have an interface.\n",
    "\n",
    "Both can be played:\n",
    "> pc vs pc with and without comunication\n",
    ">\n",
    "> pc vs human without comunication\n",
    ">\n",
    "> human vs human without comunication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ataxx:\n",
    "    def __init__(self,size):\n",
    "        self.size = size\n",
    "        self.action_size = self.act_size()\n",
    "\n",
    "    def make_s0(self):\n",
    "        #used only for testing and debugging\n",
    "        matrix = np.zeros((self.size, self.size), dtype=int)\n",
    "        matrix[0][0] = 1 #white\n",
    "        matrix[self.size-1][self.size-1] = 1 #white\n",
    "        matrix[self.size-1][0] = -1 #black\n",
    "        matrix[0][self.size-1] = -1 #black\n",
    "        return matrix\n",
    "\n",
    "    def place(self,x,y,state,player):\n",
    "        state[x][y] = player\n",
    "        return state\n",
    "      \n",
    "    def remove(self,x,y,state):\n",
    "        state[x][y] = 0\n",
    "        return state\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.state\n",
    "    \n",
    "    def count(self,player,state): \n",
    "        x, _ = np.where(state == player)\n",
    "        return len(x)\n",
    "    \n",
    "    def change_turn(self,player):\n",
    "        return -player\n",
    "\n",
    "    def get_color(self,player):\n",
    "        if player == 1:\n",
    "            return 'white'\n",
    "        else:\n",
    "            return 'black'\n",
    "    \n",
    "    def distance(self,x,y,movex,movey):                 \n",
    "        difx=abs(x-movex)\n",
    "        dify=abs(y-movey)\n",
    "        return max(difx,dify)\n",
    "        \n",
    "    def isjump(self,x,y,movex,movey):\n",
    "        return self.distance(x,y,movex,movey)==2    \n",
    "    \n",
    "    def isfree(self,x,y,state):                               \n",
    "        return state[x][y]==0\n",
    "    \n",
    "    def infect_neighbours(self,x,y,state,player):\n",
    "        infection_space = self.radius_space(x,y,1)\n",
    "        for (line,col) in infection_space:\n",
    "            if state[line][col] != 0 and state[line][col] != 3:\n",
    "                self.place(line,col,state,player)  \n",
    "    \n",
    "    def radius_space(self,x,y,radius): \n",
    "        # All the possible moves for a pick (x,y)\n",
    "        # The radius is either 1 or 2\n",
    "        radius_space = []   \n",
    "        # Check radius space\n",
    "        bottom = x+radius\n",
    "        left = y-radius\n",
    "        top = x-radius\n",
    "        right  = y+radius\n",
    "        # Check if the radius space is inside the board\n",
    "        while left<0:\n",
    "            left+=1\n",
    "        while top<0:\n",
    "            top+=1\n",
    "        while right > (self.size-1):\n",
    "            right-=1\n",
    "        while bottom > (self.size-1):\n",
    "            bottom-=1\n",
    "        # From radius space select all positions (empty included)\n",
    "        for line in range(top,bottom+1):           \n",
    "            for col in range(left, right+1):        \n",
    "                radius_space.append((line,col)) \n",
    "        return radius_space  \n",
    "    \n",
    "    def possible_picks(self,state, player):                           \n",
    "        # All the possible picks for the player\n",
    "        x, y = np.where(state == player)\n",
    "        return list(zip(x,y))\n",
    "    \n",
    "    def picked_action_space(self,x,y,state):\n",
    "        # Action space from picked (x,y) (radius 2 and 1)\n",
    "        picked_action_space = []\n",
    "        aux = self.radius_space(x,y,2)\n",
    "        for (line,col) in aux:\n",
    "            if self.isfree(line,col,state):\n",
    "                picked_action_space.append((line,col))\n",
    "        return picked_action_space  # Returns list of tuples \n",
    "\n",
    "    def action_space(self,state,player):\n",
    "        #Returns action space for the current state and player\n",
    "        all_actions = []\n",
    "        picks = self.possible_picks(state,player)\n",
    "        for (x,y) in picks:\n",
    "            for (movex,movey) in self.picked_action_space(x,y,state):\n",
    "                if movex is not None and movey is not None:\n",
    "                    action = (x,y,movex,movey)      \n",
    "                    all_actions.append(action)\n",
    "        return all_actions \n",
    "    \n",
    "    def play_move(self,action,state,player):\n",
    "        #the move comes already verified\n",
    "        self.place(action[2], action[3],state,player)\n",
    "        #if jump remove father piece\n",
    "        if self.isjump(action[0], action[1], action[2], action[3]):\n",
    "            self.remove(action[0], action[1],state)\n",
    "        self.infect_neighbours(action[2], action[3],state,player)\n",
    "        return state.copy() #copy just in case\n",
    "    \n",
    "    def verify_move(self,action, state, player):\n",
    "        return action in self.action_space(state,player)\n",
    "    \n",
    "    def get_random_move(self,state,player):\n",
    "        #For playing Randomly\n",
    "        state = state.copy()#just in case\n",
    "        action_space = self.action_space(state,player)\n",
    "        action = action_space[np.random.randint(0,len(action_space))]\n",
    "        return action\n",
    "            \n",
    "    def add_to_lastnine(self,state,last_nine):  \n",
    "        #receives last nine and updates it\n",
    "        last = last_nine.copy()\n",
    "        novo = state.copy()\n",
    "        if (len(last)==9):\n",
    "            last.pop(0)\n",
    "            last.append(novo)\n",
    "        else:\n",
    "            last.append(novo)\n",
    "        return last.copy()\n",
    "    \n",
    "    def is_threefold_repetition_rule(self,last_nine):\n",
    "        dic={}\n",
    "        if  last_nine and len(last_nine)==9:\n",
    "            for i in last_nine:\n",
    "                #trasformar em tuplo(hashable) para poder ser chave do dicionário\n",
    "                tuplo = tuple(map(tuple, i))\n",
    "                if tuplo in dic.keys():\n",
    "                    dic[tuplo] += 1\n",
    "                else:\n",
    "                    dic[tuplo] = 1\n",
    "            for tuplo in dic.keys():\n",
    "                if dic[tuplo]>=3:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def isfull(self, state):\n",
    "        x, _ =np.where(state == 0)\n",
    "        if len(x)>0:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def is_stuck(self, state, player):\n",
    "        return ((len(self.action_space(state, player)) == 0) and (not self.isfull(state)))\n",
    "    \n",
    "    def is_finished(self, state, player, last_nine):\n",
    "        if self.isfull(state) or self.is_stuck(state,player) or self.is_threefold_repetition_rule(last_nine):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def winner(self, state, player, last_nine):\n",
    "        #if_Full\n",
    "        if self.isfull(state):\n",
    "            print(\"Game is Full!\")\n",
    "            if (self.count(1,state) - self.count(-1,state) > 0):\n",
    "                return 1\n",
    "            elif (self.count(1,state) - self.count(-1,state) < 0):\n",
    "                return -1\n",
    "            else:                \n",
    "                return 0\n",
    "            \n",
    "        #if_Stuck\n",
    "        elif self.is_stuck(state, player):\n",
    "            print(player, \"is stuck!\")\n",
    "            self_count = self.count(state,player)\n",
    "            opponent_possible_count = self.size*self.size - self_count\n",
    "            if self_count > opponent_possible_count:\n",
    "                return player\n",
    "            elif self_count < opponent_possible_count:\n",
    "                return -player\n",
    "            else:\n",
    "                return 0\n",
    "        \n",
    "        elif self.is_threefold_repetition_rule(last_nine):\n",
    "            # não queremos que o modelo aprenda a ganhar por esta regra!\n",
    "            print(\"Threefold Repetition Rule!\")\n",
    "            return 0\n",
    "    \n",
    "        return 0    #other non imagined situation\n",
    "            \n",
    "\n",
    "\n",
    "    #______________________Functions_for_Alpha_Zero____________________#\n",
    "\n",
    "    def get_value_and_terminated(self,state,player):\n",
    "        if self.isfull(state):\n",
    "            if (self.count(1,state) != self.count(-1,state)):\n",
    "             return 1, True      # White or Black wins\n",
    "            else:\n",
    "                return 0, True   # Draw\n",
    "        if self.is_stuck(state,player):\n",
    "            if(player == 1):\n",
    "                color_turn = 'white'\n",
    "            else:\n",
    "                color_turn = 'black'\n",
    "            self_count = self.count(player,state)\n",
    "            opponent_possible_count = self.size*self.size - self_count\n",
    "            if(self_count != opponent_possible_count):\n",
    "                return 1, True    # White or Black wins  \n",
    "            else:\n",
    "                return 0, True  # Draw\n",
    "        return 0, False\n",
    "    \n",
    "    def get_opponent_value(self, value):\n",
    "        return -value\n",
    "    \n",
    "    def change_perspective(self, state):\n",
    "        # Changes the state so that 1's become -1's and vice versa.\n",
    "        # Useful for the algorithm\n",
    "        return state*-1 \n",
    "    \n",
    "    # Some functions useful for the neural network\n",
    "    def get_encoded_state(self, state):\n",
    "        encoded_state = np.stack(\n",
    "            (state == -1, state == 0, state == 1)\n",
    "        ).astype(np.float32)\n",
    "        \n",
    "        # AlphaParallel modifcation\n",
    "        if len(state.shape) == 3:\n",
    "            encoded_state = np.swapaxes(encoded_state, 0, 1)\n",
    "        \n",
    "        return encoded_state\n",
    "    \n",
    "    def action_dict(self):\n",
    "        # Turns all possible actions into a dictionary \n",
    "        actions = self.get_all_actions()\n",
    "        dic = {}\n",
    "        for action in actions:\n",
    "            dic[action] = 0.0   \n",
    "        return dic\n",
    "    \n",
    "    def get_all_actions(self):\n",
    "        # Gets all the possible actions \n",
    "        all_actions = []\n",
    "        empty_board = np.zeros((self.size, self.size), dtype=int)\n",
    "        # All possible picks\n",
    "        x,y = np.where(empty_board == 0)\n",
    "        picks = list(zip(x, y))\n",
    "        for (x,y) in picks:\n",
    "            for (movex,movey) in self.picked_action_space(x,y,empty_board):\n",
    "                if movex is not None and movey is not None:\n",
    "                    action = (x,y,movex,movey)      \n",
    "                    all_actions.append(action)\n",
    "        return all_actions \n",
    "    \n",
    "    def act_size(self):\n",
    "        return len(self.get_all_actions())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interface Attax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class interfaceAtaxx():\n",
    "\n",
    "    def __init__(self, size, game, initial_state, type_game, time_between_moves, client = None, ag = None):\n",
    "\n",
    "        self.size = size\n",
    "        self.game = game\n",
    "        self.state = initial_state\n",
    "        self.time_between_moves = time_between_moves    #only without comunication\n",
    "\n",
    "        if client:\n",
    "            self.comunication = True\n",
    "            self.client = client\n",
    "            self.ag=ag                                  #ag1=1 ag2=-1\n",
    "            self.first=True\n",
    "            type_game = 3                               #override, pc contra pc obrigatoriamente\n",
    "\n",
    "        #first click\n",
    "        self.click=True\n",
    "        self.click_last_nine = [initial_state.copy()]\n",
    "        self.human_player = 1\n",
    "\n",
    "        self.root, self.canva = self.make_clean_canvas(canva_size)\n",
    "        self.draw_default(self.canva)\n",
    "\n",
    "        if(type_game==1):   \n",
    "            self.root.bind(\"<Button-1>\", self.human_x_human_off)\n",
    "        elif(type_game==2):\n",
    "            self.root.bind(\"<Button-1>\", self.human_vs_pc_off_random)\n",
    "        elif(type_game==3):\n",
    "            if client: \n",
    "                self.pc_x_pc_on_random(initial_state)\n",
    "            else: #ofline\n",
    "                self.pc_x_pc_off_random(initial_state)\n",
    "\n",
    "        self.root.title(\"Ataxx\")\n",
    "        self.root.mainloop()\n",
    "\n",
    "\n",
    "    def close_window(self):\n",
    "        self.root.destroy()\n",
    "\n",
    "    def update(self):\n",
    "        self.draw_default(self.canva)\n",
    "    \n",
    "    def update_state(self,state):\n",
    "        self.state = state\n",
    "\n",
    "    def draw_default(self,canva):\n",
    "        for i in range (0,canva_size,self.division_size(self.size,canva_size)):\n",
    "            canva.create_line(i,0,i,canva_size, fill=\"black\",width=2)\n",
    "            canva.create_line(0,i,canva_size,i, fill=\"black\",width=2)\n",
    "        #x,y=self.game.ocuppied_pos()\n",
    "        matriz=self.state\n",
    "        for x in range(self.size):\n",
    "            for y in range(self.size):\n",
    "                if matriz[x][y]==-1:\n",
    "                    color=color1\n",
    "                elif matriz[x][y]==1:\n",
    "                    color=color2\n",
    "                elif matriz[x][y]==0:\n",
    "                    color='#FFDEAD'\n",
    "                else:# matriz[x][y]==3:\n",
    "                    color='red'\n",
    "                self.draw(canva,color,x,y)\n",
    "    \n",
    "    def draw(self,canva,agentcolor,x,y):\n",
    "        sqr_size=self.division_size(self.size,canva_size)\n",
    "        canva.create_rectangle(x*sqr_size,y*sqr_size,(x+1)*sqr_size-1,(y+1)*sqr_size-1, fill=agentcolor, outline=\"#8B4513\")    \n",
    "\n",
    "    def division_size(self,grid,size):\n",
    "        return int(size/grid)\n",
    "        \n",
    "    def make_clean_canvas(self, x=700, y=700):\n",
    "        base=Tk()\n",
    "        base.geometry(f'{x}x{y}')\n",
    "        tela=Canvas(base, bg=\"black\", height=y,width=x)\n",
    "        tela.pack()\n",
    "        return base,tela\n",
    "\n",
    "    def make_clean_frame(self,x=150,y=200):\n",
    "        base=Tk()\n",
    "        base.geometry(f'{x}x{y}')\n",
    "        frame=ttk.Frame(base,padding=10)\n",
    "        frame.grid()\n",
    "        return base,frame\n",
    "\n",
    "    def human_x_human_off(self, event):\n",
    "        posicao_grelha = [event.x, event.y]\n",
    "        posicao_logica = [int(posicao_grelha[0] / self.division_size(self.size,canva_size)),\n",
    "                          int(posicao_grelha[1] / self.division_size(self.size,canva_size))]\n",
    "\n",
    "        if 0 <= posicao_logica[0] < self.size and 0 <= posicao_logica[1] < self.size:\n",
    "            if not self.game.is_finished(self.state, self.human_player, self.click_last_nine):\n",
    "                if self.click:\n",
    "                    self.x = posicao_logica[0]\n",
    "                    self.y = posicao_logica[1]\n",
    "                    if self.state[self.x][self.y] == self.human_player:\n",
    "                        print('Valid pick')\n",
    "                        self.click = False\n",
    "                    else:\n",
    "                        self.click = True\n",
    "                        print('Invalid pick')\n",
    "                else:\n",
    "                    self.movex = posicao_logica[0]\n",
    "                    self.movey = posicao_logica[1]\n",
    "\n",
    "                    move = (self.x, self.y, self.movex, self.movey)\n",
    "                    if self.game.verify_move(move, self.state, self.human_player):\n",
    "                        # Player playing\n",
    "                        self.state = self.game.play_move(move, self.state, self.human_player)\n",
    "                        self.click_last_nine = self.game.add_to_lastnine(self.state, self.click_last_nine)\n",
    "                        self.update()\n",
    "                        self.root.update_idletasks()\n",
    "                        self.human_player = -self.human_player\n",
    "                        self.root.title(\".BLACK.\" if self.human_player == 1 else \".WHITE.\")\n",
    "                        self.update()\n",
    "                        self.root.update_idletasks()\n",
    "\n",
    "                        if self.game.is_finished(self.state, self.human_player, self.click_last_nine):\n",
    "                            winner = self.game.winner(self.state, self.human_player, self.click_last_nine)\n",
    "                            winner_name = 'WHITE' if winner == 1 else ('BLACK' if winner == -1 else 'DRAW')\n",
    "                            print(\"Game Over - Winner: \" + winner_name)\n",
    "                            self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "                            time.sleep(5)\n",
    "                            self.root.destroy()\n",
    "\n",
    "                        self.click = True  # Switch player turns\n",
    "                    else:\n",
    "                        print(\"Invalid move\")\n",
    "                        self.root.title(\"INVALID MOVE...\")\n",
    "                        self.click = True\n",
    "\n",
    "                    self.click = True\n",
    "                    self.root.update()\n",
    "            else:\n",
    "                winner = self.game.winner(self.state, self.human_player, self.click_last_nine)\n",
    "                winner_name = 'WHITE' if winner == 1 else ('BLACK' if winner == -1 else 'DRAW')\n",
    "                print(\"Game Over - Winner: \" + winner_name)\n",
    "                self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "                time.sleep(5)\n",
    "                self.root.destroy()\n",
    "        else:\n",
    "            print(\"Pick or move out of range\")\n",
    "            self.root.title(\"INVALID POSITION...\")\n",
    "\n",
    "    def pc_x_pc_off_random(self,s):\n",
    "        player = 1\n",
    "        last_nine = [s]\n",
    "        print('start_game')\n",
    "        print(s)\n",
    "\n",
    "        def play_next_move(s, last_nine , player):\n",
    "            if not self.game.is_finished(s, player, last_nine):\n",
    "\n",
    "                print('white' if player == 1 else 'black')\n",
    "                move = self.game.get_random_move(s,player)\n",
    "                s = self.game.play_move(move, s, player)\n",
    "                last_nine = self.game.add_to_lastnine(s, last_nine)\n",
    "                print('move: ', move)\n",
    "                print(s)\n",
    "\n",
    "                self.update_state(s)\n",
    "                self.update()\n",
    "                player = -player\n",
    "                #this works as a cilce with time.slepp of 1000 miliseconds\n",
    "                self.root.after(self.time_between_moves, lambda: play_next_move(s, last_nine, player))   \n",
    "            else:\n",
    "                winner = self.game.winner(s, player, last_nine)\n",
    "                winner_name = 'white' if winner == 1 else ('black' if winner == -1 else 'draw')\n",
    "                print(\"Game Over - Winner: \" + winner_name)\n",
    "                self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "\n",
    "        self.update_state(s)\n",
    "        self.update()\n",
    "        self.root.after(self.time_between_moves, lambda: play_next_move(s, last_nine, player))\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def human_vs_pc_off_random(self, event):\n",
    "        posicao_grelha = [event.x, event.y]\n",
    "        posicao_logica = [int(posicao_grelha[0]/self.division_size(self.size,canva_size)),int(posicao_grelha[1]/self.division_size(self.size,canva_size))]\n",
    "\n",
    "        if 0 <= posicao_logica[0] < self.size and 0 <= posicao_logica[1] < self.size:\n",
    "            player = 1 #we start with the white\n",
    "            if not self.game.is_finished(self.state, player, self.click_last_nine):\n",
    "\n",
    "                if self.click==True:\n",
    "                    self.x=posicao_logica[0]\n",
    "                    self.y=posicao_logica[1]\n",
    "                    if self.state[self.x][self.y]==player:\n",
    "                        print('valid pick')\n",
    "                        self.click=False\n",
    "                    else:\n",
    "                        self.click=True\n",
    "                        print('invalid pick')\n",
    "                else:\n",
    "                    self.movex=posicao_logica[0]\n",
    "                    self.movey=posicao_logica[1]\n",
    "\n",
    "                    move = (self.x,self.y,self.movex,self.movey)\n",
    "\n",
    "                    #after getting all info to play\n",
    "                    if self.game.verify_move(move,self.state,player):\n",
    "                        #me playing\n",
    "                        self.state = self.game.play_move(move, self.state, player)\n",
    "                        self.click_last_nine = self.game.add_to_lastnine(self.state, self.click_last_nine)\n",
    "                        self.update()\n",
    "                        self.root.update_idletasks()\n",
    "                        player = -player\n",
    "                        self.root.title(\".BLACK.\")\n",
    "                        self.update()\n",
    "                        self.root.update_idletasks()\n",
    "\n",
    "                        if self.game.is_finished(self.state, player, self.click_last_nine):\n",
    "                            winner = self.game.winner(self.state, player, self.click_last_nine)\n",
    "                            winner_name = 'white' if winner == 1 else ('black' if winner == -1 else 'draw')\n",
    "                            self.update()\n",
    "                            self.root.update_idletasks()\n",
    "                            print(\"Game Over - Winner: \" + winner_name)\n",
    "                            self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "                            time.sleep(5)\n",
    "                            self.root.destroy()\n",
    "\n",
    "                        #pc playing\n",
    "                        time.sleep((self.time_between_moves/1000)) #wait 1 second\n",
    "                        move = self.game.get_random_move(self.state,player)\n",
    "                        self.state = self.game.play_move(move, self.state, player)\n",
    "                        self.click_last_nine = self.game.add_to_lastnine(self.state, self.click_last_nine)\n",
    "                        self.root.title(\"Ataxx: White playing\")\n",
    "                        self.update()\n",
    "                        self.root.update_idletasks()\n",
    "                        player = -player\n",
    "                        self.click=True \n",
    "\n",
    "                    else:\n",
    "                        print(\"invalid move\")\n",
    "                        self.root.title(\"INVALID MOVE...\")\n",
    "                        self.click=True\n",
    "\n",
    "                    self.click=True\n",
    "                    self.root.update()\n",
    "            else:\n",
    "                winner = self.game.winner(self.state, player, self.click_last_nine)\n",
    "                winner_name = 'white' if winner == 1 else ('black' if winner == -1 else 'draw')\n",
    "                self.update()\n",
    "                self.root.update_idletasks()\n",
    "                print(\"Game Over - Winner: \" + winner_name)\n",
    "                self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "                self.update()\n",
    "                self.root.update_idletasks()\n",
    "                time.sleep(5)\n",
    "                self.root.destroy()\n",
    "        else:\n",
    "            print(\"pick or move out of range\")\n",
    "            self.root.title(\"INVALID POSITION...\")\n",
    "\n",
    "    def pc_x_pc_on_random(self,s):\n",
    "        last_nine = [s]\n",
    "        player = 1\n",
    "        print('start_game')\n",
    "        print(s)\n",
    "\n",
    "        def play_next_move(s, last_nine, player):\n",
    "            if not self.game.is_finished(s,player,last_nine):   \n",
    "\n",
    "                if self.ag == 1 or not self.first:\n",
    "            # 1_PLAY & SEND___________________________________\n",
    "                    \n",
    "                    self.root.title(\":self playing: \" + self.game.get_color(player))\n",
    "                    print('white' if player == 1 else 'black')\n",
    "                    move = self.game.get_random_move(s,player)\n",
    "                    s = self.game.play_move(move, s, player)\n",
    "                    last_nine = self.game.add_to_lastnine(s, last_nine)\n",
    "                    print('move: ', move)\n",
    "                    print(s)\n",
    "                    player = -player\n",
    "\n",
    "                    #interface updates\n",
    "                    self.root.title(\":opponent playing: \" + self.game.get_color(player))\n",
    "                    self.update_state(s)\n",
    "                    self.update()\n",
    "                    self.root.update_idletasks()\n",
    "                    self.root.title(\":opponent playing: \" + self.game.get_color(player))\n",
    "        \n",
    "                    #SEND MOVE\n",
    "                    move_message = self.client.stringify_move_ataxx(move[0], move[1], move[2], move[3])\n",
    "                    time.sleep(1)\n",
    "                    self.client.client_socket.send(move_message.encode())\n",
    "                    print(\"Send:\", move_message)\n",
    "\n",
    "\n",
    "            # 2_RECEIVE & PLAY___________________________________\n",
    "                    # play as the other side\n",
    "                    response = self.client.client_socket.recv(1024).decode()\n",
    "                    print(f\"Server Response1: {response}\")\n",
    "                    if \"END\" in response:\n",
    "                        return #else:\n",
    "\n",
    "                    print('white' if player == 1 else 'black')\n",
    "                    move = self.client.decode_stringify_move_ataxx(response)\n",
    "                    s = self.game.play_move(move, s, player)\n",
    "                    last_nine = self.game.add_to_lastnine(s, last_nine)\n",
    "                    print('move: ', move)\n",
    "                    print(s)\n",
    "                    player = -player\n",
    "\n",
    "                    #interface updates\n",
    "                    self.root.title(\":self playing: \" + self.game.get_color(player))\n",
    "                    self.update_state(s)\n",
    "                    self.update()\n",
    "                    self.root.update_idletasks()\n",
    "                    self.root.title(\":self playing: \" + self.game.get_color(player))\n",
    "\n",
    "    \n",
    "                else: # the other client\n",
    "                    self.first = False\n",
    "                    self.root.title(\":opponent playing: \" + self.game.get_color(player))\n",
    "                    #the other don't change the player, because he will play for our side first.\n",
    "                    response = self.client.client_socket.recv(1024).decode()\n",
    "                    print(f\"Server Response2: {response}\")\n",
    "    \n",
    "                    if \"END\" in response:\n",
    "                        return\n",
    "    \n",
    "                    print('white' if player == 1 else 'black')\n",
    "                    move = self.client.decode_stringify_move_ataxx(response)\n",
    "                    s = self.game.play_move(move, s, player)\n",
    "                    last_nine = self.game.add_to_lastnine(s, last_nine)\n",
    "                    print('move: ', move)\n",
    "                    print(s)\n",
    "                    player = -player\n",
    "\n",
    "                    #interface updates\n",
    "                    self.root.title(\":self playing: \" + self.game.get_color(player))\n",
    "                    self.update_state(s)\n",
    "                    self.update()\n",
    "                    self.root.update_idletasks()\n",
    "                    self.root.title(\":self playing: \" + self.game.get_color(player))\n",
    "                    \n",
    "\n",
    "                # Schedule the next move after a delay (in milliseconds)\n",
    "                time.sleep(1)\n",
    "                self.root.after(self.time_between_moves, lambda: play_next_move(s, last_nine, player))\n",
    "\n",
    "            else:\n",
    "                #the agent 1 is always the white\n",
    "                winner = self.game.winner(s, player, last_nine)\n",
    "                winner_name = 'white, Ag1' if winner == 1 else ('black, Ag2' if winner == -1 else 'draw')\n",
    "                print(\"Game Over - Winner: \" + winner_name)\n",
    "                self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "                self.client.client_socket.close()\n",
    "                return\n",
    "            \n",
    "        self.update_state(s)\n",
    "        self.update()\n",
    "        if self.ag == 1:\n",
    "            self.root.title(\":self playing: \" + self.game.get_color(player))\n",
    "        else:\n",
    "            self.root.title(\":opponent playing: \" + self.game.get_color(player))\n",
    "        self.root.after(self.time_between_moves, lambda: play_next_move(s, last_nine, player))\n",
    "        self.root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Go:\n",
    "\n",
    "    def __init__(self,size):\n",
    "        self.size = size\n",
    "        self.komi = 5.5             \n",
    "        self.pass_move = (-1,-1)    #this out of range move is used to pass the turn\n",
    "        #action size: total board + pass move\n",
    "        self.action_size = self.size * self.size + 1 \n",
    "    \n",
    "    def make_default_s0(self):\n",
    "        #used only for testing and debugging\n",
    "        return np.zeros((self.size, self.size), dtype=int)\n",
    "    \n",
    "    def place(self,x,y,state,player):\n",
    "        state = state.copy()                                    #copy()\n",
    "        state[x][y] = player\n",
    "        return state\n",
    "    \n",
    "    def remove(self,x,y,state):\n",
    "        state = state.copy()                                    #copy()\n",
    "        state[x][y] = 0\n",
    "        return state\n",
    "    \n",
    "    def get_color(self,player):\n",
    "        return 'black' if player == 1 else 'white'\n",
    "    \n",
    "    def get_color_of_position(self,x,y,state):\n",
    "        return self.get_color(state[x][y])\n",
    "    \n",
    "    def isfree(self,x,y,state):                               \n",
    "        return state[x][y]==0\n",
    "    \n",
    "    def get_neighbors(self, x, y) -> [(int, int)]:\n",
    "        #returns all (max: 4) neigbours, empty or not, inside board range \n",
    "        directions = [(0, 1), (1, 0), (0, -1), (-1, 0)]\n",
    "        liberties = [(x + dx, y + dy) for dx, dy in directions if 0 <= x + dx < self.size and 0 <= y + dy < self.size]\n",
    "        return liberties\n",
    "\n",
    "    def get_liberties(self,x,y,state):\n",
    "        #returns empty neigbours\n",
    "        directions = [(0, 1), (1, 0), (0, -1), (-1, 0)]\n",
    "        liberties = [(x + dx, y + dy) for dx, dy in directions if (0 <= x + dx < self.size and 0 <= y + dy < self.size and state[x + dx][y + dy] == 0)]\n",
    "        return liberties\n",
    "    \n",
    "    def has_liberties(self,x,y,state):\n",
    "        return  len(self.get_liberties(x,y,state)) > 0\n",
    "    \n",
    "    def group_has_liberty(self,group,state):\n",
    "        #if group is not limited\n",
    "        for stone in group:\n",
    "            x, y = stone\n",
    "            liberties = self.get_liberties(x, y, state)\n",
    "            if liberties:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def identify_limited_groups_by_player(self,state, player) -> [{(int, int)}]: \n",
    "        #retorna apenas grupos sem liberties\n",
    "        #using dfs, expande until no more of the same color\n",
    "        state = state.copy()\n",
    "    #{\n",
    "        limited_group_list = []\n",
    "        value = player\n",
    "        positions = list(map(tuple, np.argwhere(state == value)))\n",
    "        visited = set()\n",
    "        group = set()        \n",
    "        def identify_group(x,y,state):\n",
    "        #{  um grupo que cotem x,y\n",
    "            def dfs(a,b,state):\n",
    "            #{  propagação por dfs\n",
    "                sx, sy = a, b\n",
    "                if (\n",
    "                    0 <= sx < self.size\n",
    "                    and 0 <= sy < self.size\n",
    "                    and (sx, sy) not in visited\n",
    "                    and state[sx][sy] == state[x][y]\n",
    "                ):\n",
    "                    visited.add((sx, sy))\n",
    "                    group.add((sx, sy))\n",
    "                    for neighbour in self.get_neighbors(sx, sy):\n",
    "                        dfs(neighbour[0], neighbour[1],state)\n",
    "            #{\n",
    "            if 0 <= x < self.size and 0 <= y < self.size:\n",
    "                dfs(x, y,state)\n",
    "        #}\n",
    "        for (x,y) in positions:\n",
    "            if (x,y) not in visited:\n",
    "                identify_group(x,y,state)\n",
    "                if not self.group_has_liberty(group,state): #Está verificado se grupo está preso\n",
    "                    limited_group_list.append(group)    \n",
    "                group = set() #reset group\n",
    "    #}\n",
    "        return limited_group_list\n",
    "    \n",
    "    def identify_group_by_position(self, x, y, state):\n",
    "        #to avoid checking all board in some plays\n",
    "        visited = set()\n",
    "        group = set()\n",
    "        def dfs(a, b, state):\n",
    "            # o dfs está aqui dentro porque precisa do x,y\n",
    "            sx, sy = a, b\n",
    "            if (\n",
    "                0 <= sx < self.size\n",
    "                and 0 <= sy < self.size\n",
    "                and (sx, sy) not in visited\n",
    "                and state[sx][sy] == state[x][y]\n",
    "            ):\n",
    "                visited.add((sx, sy))\n",
    "                group.add((sx, sy))\n",
    "                for neighbour in self.get_neighbors(sx, sy):\n",
    "                    dfs(neighbour[0], neighbour[1])\n",
    "        if 0 <= x < self.size and 0 <= y < self.size:\n",
    "            dfs(x, y, state)\n",
    "        return group\n",
    "\n",
    "    def capture_all(self, limited_group_list, state):\n",
    "        #if limited group after a play,it might be captured, \n",
    "        #temos que retornar peças capturadas, para subtrair no final\n",
    "        captures = {1: 0, -1: 0}\n",
    "        state = state.copy()                                                            \n",
    "        for group in limited_group_list:\n",
    "            for (x,y) in group:\n",
    "                if state[x][y] == 1:\n",
    "                    captures[1] += 1\n",
    "                if state[x][y] == -1:\n",
    "                    captures[-1] += 1\n",
    "                state[x][y] = 0\n",
    "\n",
    "        return state, captures\n",
    "        \n",
    "    def add_to_last_three(self, state, last_three):\n",
    "        #we are doing a lot of copies, because of mtcs branching\n",
    "        last_three = last_three.copy()                           #copy()\n",
    "        state = state.copy()\n",
    "        if (len(last_three) >= 3):\n",
    "            last_three.pop(0)\n",
    "            last_three.append(state)\n",
    "        else:\n",
    "            last_three.append(state)\n",
    "        return last_three\n",
    "        \n",
    "    def is_Ko(self, next_state, last_three): \n",
    "        #verify ko rule by comparing to the penultimate state\n",
    "        last_three = last_three.copy()\n",
    "        # !!-> state corresponde ao próximo estado <-!! #\n",
    "        if len(last_three) == 3:\n",
    "            b = np.array_equal(last_three[1],next_state)\n",
    "            return b\n",
    "        elif len(last_three) == 2:\n",
    "            b = np.array_equal(last_three[0],next_state)\n",
    "            return b\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def is_valid_move(self, move, state, player, last_three):\n",
    "        #check Suicide and Ko rules\n",
    "        last_three = last_three.copy()\n",
    "        state = state.copy()\n",
    "        moveX, moveY = move[0] , move[1]\n",
    "\n",
    "        if (moveX,moveY) == (-1,-1):\n",
    "            return True\n",
    "        #se posição é vazia\n",
    "        if state[moveX][moveY] == 0:\n",
    "            \n",
    "            #First we place\n",
    "            middle_state = self.place(moveX, moveY, state, player) \n",
    "\n",
    "            #verify if our move would captures opponent\n",
    "            opponent_verify = 1 if player == -1 else -1\n",
    "            opponent_limited_groups = self.identify_limited_groups_by_player(middle_state, opponent_verify)\n",
    "            opponent_capture = True if opponent_limited_groups else False  \n",
    "\n",
    "            #verify if our move would captures ourself(SUICIDE verification)\n",
    "            self_limited_groups = self.identify_limited_groups_by_player(middle_state, player)\n",
    "            self_capture = True if self_limited_groups else False\n",
    "            #if only capture ourself -> suicide\n",
    "            isSuicide = (not opponent_capture and self_capture)  \n",
    "            if not isSuicide:\n",
    "                future_resulting_not_suicide_state, _  = self.capture_all(opponent_limited_groups,middle_state)\n",
    "                isKo = self.is_Ko(future_resulting_not_suicide_state, last_three)\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "            is_valid = ((not isSuicide) and (not isKo))\n",
    "            return is_valid\n",
    "        else: \n",
    "            return False\n",
    "            \n",
    "        \n",
    "    def action_space(self,state, player, last_three): #---------------------------->DEAL WITH PASS MOVE\n",
    "        #veryfing Ko and suicide and empty places\n",
    "        action_space = []\n",
    "        possible_moves = list(map(tuple, np.argwhere(state == 0)))\n",
    "        for move in possible_moves:\n",
    "            isValid = self.is_valid_move(move, state, player, last_three)\n",
    "            if isValid:\n",
    "                action_space.append(move)\n",
    "        action_space.append(self.pass_move)\n",
    "        return action_space\n",
    "    \n",
    "    def play_move(self,move,state,player): \n",
    "        state = state.copy()\n",
    "        #**ELE_JÁ_VEM_VERIFICADO_REMOVER_EM_PRINCPIO**#\n",
    "        if move == (-1,-1) or move is None:\n",
    "            return state, {1:0,-1:0}\n",
    "        else:\n",
    "            x = move[0]\n",
    "            y = move[1]\n",
    "            state = self.place(x,y,state,player)\n",
    "            capture = -1 if player == 1 else 1\n",
    "            limited_group_list = self.identify_limited_groups_by_player(state, capture)\n",
    "            state, captures = self.capture_all(limited_group_list,state)\n",
    "            return state, captures\n",
    "\n",
    "    def get_random_move(self, state, player, last_three):\n",
    "        action_space = self.action_space(state, player, last_three)\n",
    "        if action_space:\n",
    "            move = action_space[np.random.randint(0,len(action_space))]\n",
    "            return move\n",
    "        else:\n",
    "        #Fazer algo apropriado se action_space vazio\n",
    "             print(\"A lista action_space está vazia.\")\n",
    "             \n",
    "    def is_finished(self, state, last_three):\n",
    "        state = state.copy()\n",
    "        #if full board or both passes -> (last_three staet are equal)\n",
    "        if len(last_three) < 3:\n",
    "            return False\n",
    "        first = last_three[0]\n",
    "        second = last_three[1]\n",
    "        third = last_three[2]\n",
    "        c, _ = np.where(state == 0)\n",
    "        return len(c) == 0 or (np.array_equal(first, second) and np.array_equal(second, third))\n",
    "\n",
    "    def identify_territory_by_player(self, state, player) -> [{(int, int)}]:\n",
    "    #we start by identifying all territories based on his probable owner. By player\n",
    "        state = state.copy()\n",
    "        #liberties visitadas + peças visitadas\n",
    "        liberties_visited = set()\n",
    "        player_pieces_visited = set()\n",
    "        #territorio (empty positions) + peças do jogador\n",
    "        territories = [] # list of sets of tuples os 2 ints\n",
    "        player_pieces = list(map(tuple, np.argwhere(state == player)))\n",
    "\n",
    "        #identify empty groups by liberty position\n",
    "        def identify_territory_by_liberty_position(x, y, state):\n",
    "            state = state.copy()\n",
    "            territory = set()\n",
    "            #dfs search\n",
    "            def dfs(a, b, state):\n",
    "                sx, sy = a, b\n",
    "                if (\n",
    "                    0 <= sx < self.size\n",
    "                    and 0 <= sy < self.size\n",
    "                    and (sx, sy) not in liberties_visited\n",
    "                    and (state[sx][sy] == 0)\n",
    "                ):\n",
    "                    liberties_visited.add((sx, sy))\n",
    "                    territory.add((sx, sy))\n",
    "                    #apenas se tivermos liberty disponivel é que continuamos a expansão\n",
    "                    for libs in self.get_liberties(sx, sy, state):  \n",
    "                        dfs(libs[0], libs[1], state)\n",
    "            #aqui chamamos dfs          \n",
    "            if 0 <= x < self.size and 0 <= y < self.size:\n",
    "                dfs(x, y, state)\n",
    "            return territory\n",
    "\n",
    "        #start from empty positions near player pieces\n",
    "        for (x,y) in player_pieces:\n",
    "            if (x,y) not in player_pieces_visited:\n",
    "                player_pieces_visited.add((x,y))\n",
    "                #get liberties of player pieces and start search with one of them\n",
    "                liberties = self.get_liberties(x,y,state)\n",
    "                for (x,y) in liberties:\n",
    "                    if (x,y) not in liberties_visited:\n",
    "                        territory = identify_territory_by_liberty_position(x,y,state)\n",
    "                        territories.append(territory)\n",
    "                    \n",
    "        return territories\n",
    "\n",
    "    def check_territory_owner(self, territory, state, player):\n",
    "    #each territory:a) identify the owner of a territory, b)we highlight(9,-9,5) the positions that belong to the owner & return it. c)count and remove the dead pieces on enemy territory. \n",
    "        state = state.copy()\n",
    "        null_state = state.copy()\n",
    "        my_state = state.copy()\n",
    "        opponent_state = state.copy()\n",
    "        me = player\n",
    "        opponent = -1 if player == 1 else 1\n",
    "\n",
    "        #fill territory with opponent pieces, and observe...\n",
    "        for (x, y) in territory:\n",
    "            state[x][y] = opponent\n",
    "\n",
    "        #Listas de grupos limitados. Por jogador\n",
    "        opponent_limited_created = self.identify_limited_groups_by_player(state, opponent)\n",
    "        me_limited_created = self.identify_limited_groups_by_player(state, me)\n",
    "\n",
    "        #Se com o fill, nenhum limited criado -> territorio neutro, e preenchemos com numero 0\n",
    "        if len(opponent_limited_created) == 0 and len(me_limited_created) == 0:\n",
    "            for (x,y) in territory:\n",
    "                null_state[x][y] = 5\n",
    "            return {'owner': 0,'masked': null_state,'removed': 0} #Dono, masked with neutral: 0, pieces removed.\n",
    "        \n",
    "        #se só adeversário perde com o fill, então territorio é meu\n",
    "        elif len(opponent_limited_created) >0 and len(me_limited_created) == 0:\n",
    "            opponent_removed_pieces = -len(territory) #a contar com peças que já estavam lá\n",
    "            for each_fill in opponent_limited_created:\n",
    "                for (x,y) in each_fill:\n",
    "                    opponent_removed_pieces+=1\n",
    "                    my_state[x][y] = me*9   #estes territórios são meus\n",
    "            return {'owner': me,'masked': my_state,'removed': opponent_removed_pieces}\n",
    "        \n",
    "        #se só eu perco com o fill, então territorio é do adeversário, e as minhas peças são removidas e subtraidas no meu território total\n",
    "        elif len(opponent_limited_created) == 0 and len(me_limited_created) > 0:\n",
    "            my_removed_pieces = -len(territory)\n",
    "            for each_fill in me_limited_created:\n",
    "                for (x,y) in each_fill:\n",
    "                    my_removed_pieces+=1\n",
    "                    opponent_state[x][y] = opponent*9\n",
    "            return {'owner': opponent,'masked': opponent_state,'removed': my_removed_pieces}\n",
    "        \n",
    "        else:\n",
    "            #Para casos Dubios.\n",
    "            #Ambos > 0 -> para verificar esta condição, vamos fazer um novo fill, com as minhas peças:\n",
    "            #se eu for capturado, é do adeversário, se eu não for, é meu \n",
    "            for (x, y) in territory:\n",
    "                state[x][y] = me\n",
    "            opponent_limited_created = self.identify_limited_groups_by_player(state, opponent)\n",
    "            me_limited_created = self.identify_limited_groups_by_player(state, me)\n",
    "            #np.where -> ([],[])\n",
    "\n",
    "            #se eu for capturado, é do adeversário\n",
    "            if len(me_limited_created) >0 and len(opponent_limited_created) == 0:\n",
    "                #se eu não for capturado, é meu\n",
    "                my_removed_pieces = -len(territory)\n",
    "                for each_fill in me_limited_created:\n",
    "                    for (x,y) in each_fill:\n",
    "                        my_removed_pieces+=1\n",
    "                        opponent_state[x][y] = opponent*9\n",
    "                return {'owner': opponent,'masked': opponent_state,'removed': my_removed_pieces}\n",
    "\n",
    "            #se eu não for capturado, é meu\n",
    "            else:\n",
    "                for (x,y) in territory:\n",
    "                    my_state[x][y] = me*9\n",
    "                return {'owner': me,'masked': my_state,'removed': 0}\n",
    "            \n",
    "    def winner(self, state, during_game_captures):\n",
    "    #receives state & during game captures dict('player': n_captures)\n",
    "        black_captures = during_game_captures[1]\n",
    "        white_captures = during_game_captures[-1]\n",
    "        state = state.copy()\n",
    "        final_state = state.copy()\n",
    "\n",
    "        #we start by defining the possibe ownner of all territories\n",
    "        white_territories = self.identify_territory_by_player(state, -1)\n",
    "        black_territories = self.identify_territory_by_player(state, 1)\n",
    "        both = [white_territories,black_territories]\n",
    "\n",
    "        #then we verify it\n",
    "        neutral_masks = []\n",
    "        white_masks = []\n",
    "        black_masks = []\n",
    "\n",
    "        #get_information\n",
    "        for possible_own in both:\n",
    "            for territory in possible_own:\n",
    "                territory_info = self.check_territory_owner(territory,state,-1)\n",
    "\n",
    "                owner = territory_info['owner']\n",
    "                s = territory_info['masked']\n",
    "                removed = territory_info['removed']\n",
    "\n",
    "                if owner == 0:\n",
    "                    neutral_masks.append(s.copy())\n",
    "                elif owner == -1:\n",
    "                    white_masks.append(s.copy())\n",
    "                    white_captures += removed\n",
    "                else:\n",
    "                    black_masks.append(s.copy())\n",
    "                    black_captures += removed\n",
    "        \n",
    "        #apply masks -> 2º white, 3º black\n",
    "        for mask in neutral_masks:\n",
    "            #Será que 5 não prejudica o funcionamento de outras funções?????\n",
    "            neutral_points = list(map(tuple, np.argwhere(mask == 5)))\n",
    "            for (x,y) in neutral_points:\n",
    "                final_state[x][y] = 5\n",
    "        \n",
    "        for mask in white_masks:\n",
    "            white_points = list(map(tuple, np.argwhere(mask == -9)))\n",
    "            for (x,y) in white_points:\n",
    "                final_state[x][y] = -9\n",
    "\n",
    "        for mask in black_masks:\n",
    "            black_points = list(map(tuple, np.argwhere(mask == 9)))\n",
    "            for (x,y) in black_points:\n",
    "                final_state[x][y] = 9\n",
    "\n",
    "        #count points\n",
    "        white_points = self.komi + len(np.where(final_state == -9)[0]) - white_captures\n",
    "        black_points = len(np.where(final_state == 9)[0]) - black_captures\n",
    "        winner = 1 if black_points > white_points else (-1 if white_points > black_points else 0)\n",
    "        #np.where -> ([],[])\n",
    "\n",
    "        print('____final_counting___')\n",
    "        print()\n",
    "        print('Black captured:', black_captures, end=' ')\n",
    "        print('White captured:', white_captures)\n",
    "        print()\n",
    "        print('Black points:', black_points, end=' ')\n",
    "        print('White points:', white_points)\n",
    "        print()\n",
    "        print('________Winner_______: ', self.get_color(winner), ' by', abs(black_points - white_points), ' difference')\n",
    "        print(final_state)\n",
    "\n",
    "        return winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interface Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class interfaceGo():\n",
    "\n",
    "    def __init__(self, size, game, initial_state, type_game, time_between_moves, client = None, ag = None):\n",
    "        self.size = size\n",
    "        self.game = game\n",
    "        self.state = initial_state\n",
    "        self.time_between_moves = time_between_moves\n",
    "        #playing with comunication\n",
    "        if client:\n",
    "            self.comunication = True\n",
    "            self.client = client\n",
    "            self.ag=ag      #se é agente 1 ou 2\n",
    "            self.first=True\n",
    "            type_game = 3\n",
    "\n",
    "        #game features that need to be external to the game\n",
    "        self.human_last_three = []\n",
    "        self.human_captures = {1: 0, -1: 0}\n",
    "        self.human_player = 1\n",
    "\n",
    "        self.root, self.canva = self.make_clean_canvas(canva_size)\n",
    "        self.draw_default(self.canva)\n",
    "        \n",
    "        if(type_game==1):   \n",
    "            #human human\n",
    "            self.root.bind(\"<Button-1>\", self.human_x_human_off)\n",
    "            self.pass_button = ttk.Button(self.root, text=\"Pass\", command=self.make_pass_move_human_x_human)\n",
    "            #pass button\n",
    "            self.pass_button.pack(side=BOTTOM, pady=10)\n",
    "        elif(type_game==2):\n",
    "            #pc human\n",
    "            self.root.bind(\"<Button-1>\", self.human_x_pc_off_random)\n",
    "            self.pass_button = ttk.Button(self.root, text=\"Pass\", command=self.make_pass_move_human_x_pc)\n",
    "            self.pass_button.pack(side=BOTTOM, pady=10)\n",
    "        elif(type_game==3):\n",
    "            #pc pc with or without comunication\n",
    "            if client: \n",
    "                self.pc_x_pc_on_random(initial_state)\n",
    "            else: #ofline\n",
    "                self.pc_x_pc_off_random(initial_state)\n",
    "\n",
    "        self.root.title(\"Go\")\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def close_window(self):\n",
    "        self.root.destroy()\n",
    "\n",
    "    def update(self):\n",
    "        self.canva.destroy()                \n",
    "        self.canva=Canvas(self.root, bg=\"#FFDEAD\", height=canva_size,width=canva_size)\n",
    "        self.canva.pack()\n",
    "        self.draw_default(self.canva)\n",
    "    \n",
    "    def update_state(self,state):\n",
    "        self.state = state\n",
    "\n",
    "    def draw_default(self,canva):\n",
    "        for i in range (0,canva_size,self.division_size(self.size,canva_size)):\n",
    "            canva.create_line(i+go_offset,go_offset,i+go_offset,canva_size+go_offset-self.division_size(self.size,canva_size), fill=\"black\",width=4)\n",
    "            canva.create_line(go_offset,i+go_offset,canva_size+go_offset-self.division_size(self.size,canva_size),i+go_offset, fill=\"black\",width=4)\n",
    "            #time.sleep(5)\n",
    "        #x,y=self.mk.ocuppied_pos()\n",
    "        matriz=self.state\n",
    "        for x in range(self.size):\n",
    "            for y in range(self.size):\n",
    "                if matriz[x][y]==1:\n",
    "                    color=color1 #preto\n",
    "                    self.draw(canva,color,x,y)\n",
    "                elif matriz[x][y]==-1:  #branco\n",
    "                    color=color2\n",
    "                    self.draw(canva,color,x,y)\n",
    "                else:#elif matriz[x][y]==0:\n",
    "                    pass\n",
    "    \n",
    "    def draw(self,canva,agentcolor,x,y):\n",
    "        sqr_size=self.division_size(self.size,canva_size)\n",
    "        canva.create_oval((x*sqr_size)-(sqr_size/2.5)+go_offset,(y*sqr_size)-(sqr_size/2.5)+go_offset,((x+1)*sqr_size)-(sqr_size/1.5)+go_offset,((y+1)*sqr_size)-(sqr_size/1.5)+go_offset, fill=agentcolor)        \n",
    "\n",
    "    def division_size(self,grid,size):\n",
    "        return round(size/grid)\n",
    "        \n",
    "    def make_clean_canvas(self, x=canva_size, y=canva_size):\n",
    "        base=Tk()\n",
    "        base.geometry(f'{x+100}x{y+100}')\n",
    "        #tela=Canvas(base, bg=\"white\", height=y-self.division_size(grid_size,canva_size),width=x-self.division_size(grid_size,canva_size))\n",
    "        tela=Canvas(base, bg=\"#FFDEAD\", height=y,width=x)\n",
    "        tela.pack()\n",
    "        return base,tela\n",
    "\n",
    "    def make_clean_frame(self,x=150,y=200):\n",
    "        base=Tk()\n",
    "        base.geometry(f'{x}x{y}')\n",
    "        frame=ttk.Frame(base,padding=10)\n",
    "        frame.grid()\n",
    "        return base,frame\n",
    "\n",
    "    def make_pass_move_human_x_human(self):\n",
    "        #if you click pass, this is activated, move =(-1,-1)\n",
    "        print('PASS')\n",
    "        state = self.state.copy()\n",
    "        player = self.human_player\n",
    "        #if not finished\n",
    "        if not self.game.is_finished(state, self.human_last_three):\n",
    "            #jogamos e recebemos resulting state and captures. UPDATE IT\n",
    "            #UPDATE captures and last_three\n",
    "            self.human_last_three = self.game.add_to_last_three(state, self.human_last_three)\n",
    "            #update interface and players\n",
    "            self.update()\n",
    "            self.root.update_idletasks()\n",
    "            self.human_player = -player\n",
    "            self.root.title(\".BLACK.\" if self.human_player == 1 else \".WHITE.\")\n",
    "            self.update()\n",
    "            self.root.update_idletasks()\n",
    "        else:\n",
    "            winner = self.game.winner(self.state, self.human_captures)\n",
    "            winner_name = 'WHITE' if winner == -1 else ('BLACK' if winner == 1 else 'DRAW')\n",
    "            print(\"Game Over - Winner: \" + winner_name)\n",
    "            self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "            return\n",
    "\n",
    "    def human_x_human_off(self, event):\n",
    "        posicao_grelha = [event.x - go_offset+20, event.y - go_offset+20]\n",
    "        posicao_logica = [int(posicao_grelha[0] / self.division_size(self.size, canva_size)),\n",
    "                          int(posicao_grelha[1] / self.division_size(self.size, canva_size))]\n",
    "        \n",
    "          # Define os limites do tabuleiro de jogo\n",
    "        board_left = go_offset - 20\n",
    "        board_right = go_offset + 20 + self.size * self.division_size(self.size, canva_size)\n",
    "        board_top = go_offset - 20\n",
    "        board_bottom = go_offset + 20 + self.size * self.division_size(self.size, canva_size)\n",
    "         # Verifica se o evento de clique ocorreu dentro do tabuleiro de jogo\n",
    "        if not (board_left <= event.x <= board_right and board_top <= event.y <= board_bottom):\n",
    "            print(\"cursor out of range\")\n",
    "            return\n",
    "\n",
    "        if 0 <= posicao_logica[0] < self.size and 0 <= posicao_logica[1] < self.size:\n",
    "            #save move\n",
    "            move = (posicao_logica[0], posicao_logica[1])\n",
    "            #verify if game is not finished\n",
    "            if not self.game.is_finished(self.state, self.human_last_three):\n",
    "                #verify if move is valid\n",
    "                if self.game.is_valid_move(move, self.state, self.human_player, self.human_last_three.copy()):\n",
    "                    #play and update\n",
    "                    self.state, c = self.game.play_move(move, self.state, self.human_player)\n",
    "                    self.human_last_three = self.game.add_to_last_three(self.state, self.human_last_three)\n",
    "                    self.human_captures[1] += c[1]\n",
    "                    self.human_captures[-1] += c[-1]\n",
    "                    self.update()\n",
    "                    self.root.update_idletasks()\n",
    "                    self.human_player = -self.human_player\n",
    "                    self.root.title(\".BLACK.\" if self.human_player == 1 else \".WHITE.\")\n",
    "                    self.update()\n",
    "                    self.root.update_idletasks()\n",
    "                  \n",
    "            else:\n",
    "                winner = self.game.winner(self.state, self.human_captures)\n",
    "                winner_name = 'WHITE' if winner == -1 else ('BLACK' if winner == 1 else 'DRAW')\n",
    "                print(\"Game Over - Winner: \" + winner_name)\n",
    "                self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "                return\n",
    "        else:\n",
    "            print('logic position out of range')\n",
    "\n",
    "\n",
    "    def make_pass_move_human_x_pc(self):\n",
    "        player = 1 #we start with the black\n",
    "        move = (-1,-1)\n",
    "        print('PASS')\n",
    "\n",
    "\n",
    "        #if not finished\n",
    "        if not self.game.is_finished(self.state, self.human_last_three):\n",
    "            #jogamos e recebemos resulting state and captures. UPDATE IT\n",
    "            #UPDATE captures and last_three\n",
    "            self.human_last_three = self.game.add_to_last_three(self.state, self.human_last_three)\n",
    "\n",
    "            #update interface and players\n",
    "            self.update()\n",
    "            self.root.update_idletasks()\n",
    "            #passar a jogada ao pc\n",
    "            player = -player\n",
    "            self.root.title(\".BLACK.\" if self.human_player == 1 else \".WHITE.\")\n",
    "            self.update()\n",
    "            self.root.update_idletasks()\n",
    "\n",
    "        else:\n",
    "            #in case of end game\n",
    "            winner = self.game.winner(self.state, self.human_captures)\n",
    "            winner_name = 'WHITE' if winner == -1 else ('BLACK' if winner == 1 else 'DRAW')\n",
    "            print(\"Game Over - Winner: \" + winner_name)\n",
    "            self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "            return\n",
    "\n",
    "        if not self.game.is_finished(self.state, self.human_last_three):\n",
    "            #PC playing\n",
    "            time.sleep((self.time_between_moves/1000)) #wait x seconds\n",
    "            #we ask for a move, so it's forcelly a valid move\n",
    "            move = self.game.get_random_move(self.state,player,self.human_last_three)\n",
    "            #update state and captures\n",
    "            self.state, c = self.game.play_move(move, self.state, player)\n",
    "            self.human_last_three = self.game.add_to_last_three(self.state,self.human_last_three)\n",
    "            self.human_captures[1] += c[1]\n",
    "            self.human_captures[-1] += c[-1]\n",
    "\n",
    "            #interface\n",
    "            self.update()\n",
    "            self.root.update_idletasks()\n",
    "            self.root.title(\".BLACK.\" if self.human_player == 1 else \".WHITE.\")\n",
    "            self.update()\n",
    "            self.root.update_idletasks()\n",
    "        else:\n",
    "            #in case of end game\n",
    "            winner = self.game.winner(self.state, self.human_captures)\n",
    "            winner_name = 'white' if winner == 1 else ('black' if winner == -1 else 'draw')\n",
    "            self.update()\n",
    "            self.root.update_idletasks()\n",
    "            print(\"Game Over - Winner: \" + winner_name)\n",
    "            self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "            return\n",
    "\n",
    "    def human_x_pc_off_random(self, event):\n",
    "        posicao_grelha = [event.x, event.y]\n",
    "        posicao_logica = [int(posicao_grelha[0]/self.division_size(self.size,canva_size)),int(posicao_grelha[1]/self.division_size(self.size,canva_size))]\n",
    "\n",
    "        #Define board limits\n",
    "        board_left = go_offset - 20\n",
    "        board_right = go_offset + 20 + self.size * self.division_size(self.size, canva_size)\n",
    "        board_top = go_offset - 20\n",
    "        board_bottom = go_offset + 20 + self.size * self.division_size(self.size, canva_size)\n",
    "          # Verifica se o evento de clique ocorreu dentro do tabuleiro de jogo\n",
    "        if not (board_left <= event.x <= board_right and board_top <= event.y <= board_bottom):\n",
    "            print(\"cursor out of range\")\n",
    "            return\n",
    "\n",
    "        if 0 <= posicao_logica[0] < self.size and 0 <= posicao_logica[1] < self.size:\n",
    "            player = 1 #we start with the black\n",
    "            move = (posicao_logica[0], posicao_logica[1])\n",
    "            #verify if game is not finished\n",
    "            if not self.game.is_finished(self.state,self.human_last_three):\n",
    "\n",
    "                if self.game.is_valid_move(move, self.state, self.human_player, self.human_last_three):\n",
    "                        \n",
    "                        self.state, c = self.game.play_move(move, self.state, player)\n",
    "                        self.human_last_three = self.game.add_to_last_three(self.state.copy(),self.human_last_three)\n",
    "                        self.human_captures[1] += c[1]\n",
    "                        self.human_captures[-1] += c[-1]\n",
    "                        #update window after and before change player\n",
    "                        self.update()\n",
    "                        self.root.update_idletasks()\n",
    "                        player = -player\n",
    "                        self.root.title(\".BLACK.\" if self.human_player == 1 else \".WHITE.\")\n",
    "                        self.update()\n",
    "                        self.root.update_idletasks()\n",
    "            \n",
    "                        #pc playing\n",
    "                        time.sleep((self.time_between_moves/1000)) #wait x seconds\n",
    "                        move = self.game.get_random_move(self.state,player,self.human_last_three)\n",
    "                        if move == (-1,-1):\n",
    "                            print('pc PASS')\n",
    "                        self.state, c = self.game.play_move(move, self.state, player)\n",
    "                        self.human_last_three = self.game.add_to_last_three(self.state.copy(),self.human_last_three)\n",
    "                        self.human_captures[1] += c[1]\n",
    "                        self.human_captures[-1] += c[-1]\n",
    "                        self.update()\n",
    "                        self.root.update_idletasks()\n",
    "                        player = -player\n",
    "                        self.root.title(\".BLACK.\" if self.human_player == 1 else \".WHITE.\")\n",
    "        \n",
    "                else:\n",
    "                    print(\"invalid move\")\n",
    "                    self.root.title(\"INVALID MOVE...\")\n",
    "                    self.root.update()\n",
    "            else:\n",
    "                winner = self.game.winner(self.state, self.human_captures)\n",
    "                winner_name = 'white' if winner == 1 else ('black' if winner == -1 else 'draw')\n",
    "                self.update()\n",
    "                self.root.update_idletasks()\n",
    "                print(\"Game Over - Winner: \" + winner_name)\n",
    "                self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "                return\n",
    "        else:\n",
    "            print(\"pick or move out of range\")\n",
    "\n",
    "\n",
    "    def pc_x_pc_off_random(self,s):\n",
    "        player = 1\n",
    "        last_three = [s]\n",
    "        captures = {1: 0, -1: 0}\n",
    "        print('start_game')\n",
    "        print(s)\n",
    "\n",
    "        def play_next_move(s, player, last_three, captures):\n",
    "            if not self.game.is_finished(s, last_three):\n",
    "\n",
    "                print('white' if player == -1 else 'black')\n",
    "                move = self.game.get_random_move(s,player, last_three)\n",
    "                if move == (-1,-1):\n",
    "                    print('Pass')\n",
    "                    print('move: ', move)\n",
    "                    print(s)\n",
    "                    last_three = self.game.add_to_last_three(s, last_three)\n",
    "                    player = -player\n",
    "                    self.update_state(s)\n",
    "                    self.update()\n",
    "                    self.root.after(self.time_between_moves, lambda: play_next_move(s, player, last_three, captures))\n",
    "                else:\n",
    "                    s, c = self.game.play_move(move, s, player)\n",
    "                    last_three = self.game.add_to_last_three(s, last_three)\n",
    "                    captures[1] += c[1]\n",
    "                    captures[-1] += c[-1]\n",
    "                    print('move: ', move)\n",
    "                    print(s)\n",
    "\n",
    "                    self.update_state(s)\n",
    "                    self.update()\n",
    "                    player = -player\n",
    "                     #this works as a cilce with time.slepp of 1000 miliseconds\n",
    "                    self.root.after(self.time_between_moves, lambda: play_next_move(s, player, last_three, captures))\n",
    "            else:\n",
    "                winner = self.game.winner(s, captures)\n",
    "                winner_name = 'white' if winner == -1 else ('black' if winner == 1 else 'draw')\n",
    "                print(\"Game Over - Winner: \" + winner_name)\n",
    "                self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "\n",
    "        self.update_state(s)\n",
    "        self.update()\n",
    "        self.root.after(self.time_between_moves, lambda: play_next_move(s, player, last_three, captures))\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def pc_x_pc_on_random(self,s):\n",
    "        player = 1\n",
    "        last_three = [s]\n",
    "        captures = {1: 0, -1: 0}\n",
    "        print('start_game')\n",
    "        print(s)\n",
    "\n",
    "        def play_next_move(s, last_three, player, captures):\n",
    "            if not self.game.is_finished(s, last_three):   \n",
    "\n",
    "                if self.ag == 1 or not self.first:\n",
    "            # 1_PLAY & SEND___________________________________\n",
    "                    \n",
    "                    self.root.title(\":self playing: \" + self.game.get_color(player))\n",
    "                    print('white' if player == -1 else 'black')\n",
    "                    move = self.game.get_random_move(s, player, last_three)\n",
    "                    s, c = self.game.play_move(move, s, player)\n",
    "                    last_three = self.game.add_to_last_three(s, last_three)\n",
    "                    captures[1] += c[1]\n",
    "                    captures[-1] += c[-1]\n",
    "                    print('move: ', move)\n",
    "                    print(s)\n",
    "                    player = -player\n",
    "\n",
    "                    #interface updates\n",
    "                    self.root.title(\":opponent playing: \" + self.game.get_color(player))\n",
    "                    self.update_state(s)\n",
    "                    self.update()\n",
    "                    self.root.update_idletasks()\n",
    "                    self.root.title(\":opponent playing: \" + self.game.get_color(player))\n",
    "        \n",
    "                    #SEND MOVE\n",
    "                    move_message = self.client.stringify_move_go(move[0], move[1])\n",
    "                    time.sleep(1)\n",
    "                    self.client.client_socket.send(move_message.encode())\n",
    "                    print(\"Send:\", move_message)\n",
    "\n",
    "\n",
    "            # 2_RECEIVE & PLAY___________________________________\n",
    "                    # play as the other side\n",
    "                    if not self.game.is_finished(s, last_three):   \n",
    "                        response = self.client.client_socket.recv(1024).decode()\n",
    "                        print(f\"Server Response1: {response}\")\n",
    "                        if \"END\" in response:\n",
    "                            return #else:\n",
    "\n",
    "                        print('white' if player == -1 else 'black')\n",
    "                        move = self.client.decode_stringify_move_go(response)\n",
    "                        s, c = self.game.play_move(move, s, player)\n",
    "                        last_three = self.game.add_to_last_three(s, last_three)\n",
    "                        captures[1] += c[1]\n",
    "                        captures[-1] += c[-1]\n",
    "\n",
    "                        print('move: ', move)\n",
    "                        print(s)\n",
    "                        player = -player\n",
    "\n",
    "                        #interface updates\n",
    "                        self.root.title(\":self playing: \" + self.game.get_color(player))\n",
    "                        self.update_state(s)\n",
    "                        self.update()\n",
    "                        self.root.update_idletasks()\n",
    "                        self.root.title(\":self playing: \" + self.game.get_color(player))\n",
    "                    else:\n",
    "                        winner = self.game.winner(s, captures)\n",
    "                        winner_name = 'black, Ag1' if winner == 1 else ('white, Ag2' if winner == -1 else 'draw')\n",
    "                        print(\"Game Over - Winner: \" + winner_name)\n",
    "                        self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "                        self.client.client_socket.close()\n",
    "                        return\n",
    "\n",
    "    \n",
    "                else: # the other client\n",
    "                    print('other')\n",
    "                    self.first = False\n",
    "                    self.root.title(\":opponent playing: \" + self.game.get_color(player))\n",
    "                    #the other don't change the player, because he will play for our side first.\n",
    "                    response = self.client.client_socket.recv(1024).decode()\n",
    "                    print(f\"Server Response2: {response}\")\n",
    "    \n",
    "                    if \"END\" in response:\n",
    "                        return\n",
    "    \n",
    "                    print('white' if player == -1 else 'black')\n",
    "                    move = self.client.decode_stringify_move_go(response)\n",
    "                    s, c = self.game.play_move(move, s, player)\n",
    "                    last_three = self.game.add_to_last_three(s, last_three)\n",
    "                    captures[1] += c[1]\n",
    "                    captures[-1] += c[-1]\n",
    "                    print('move: ', move)\n",
    "                    print(s)\n",
    "                    player = -player\n",
    "\n",
    "                    #interface updates\n",
    "                    self.root.title(\":self playing: \" + self.game.get_color(player))\n",
    "                    self.update_state(s)\n",
    "                    self.update()\n",
    "                    self.root.update_idletasks()\n",
    "                    self.root.title(\":self playing: \" + self.game.get_color(player))\n",
    "                    \n",
    "\n",
    "                # Schedule the next move after a delay (in milliseconds)\n",
    "                time.sleep(1)\n",
    "                self.root.after(self.time_between_moves, lambda: play_next_move(s, last_three, player, captures))\n",
    "\n",
    "            else:\n",
    "                #the agent 1 is always the white\n",
    "                winner = self.game.winner(s, captures)\n",
    "                winner_name = 'black, Ag1' if winner == 1 else ('white, Ag2' if winner == -1 else 'draw')\n",
    "                print(\"Game Over - Winner: \" + winner_name)\n",
    "                self.root.title(\"Game Over - Winner: \" + winner_name)\n",
    "                self.client.client_socket.close()\n",
    "                return\n",
    "            \n",
    "        self.update_state(s)\n",
    "        self.update()\n",
    "        if self.ag == 1:\n",
    "            self.root.title(\":self playing: \" + self.game.get_color(player))\n",
    "        else:\n",
    "            self.root.title(\":opponent playing: \" + self.game.get_color(player))\n",
    "        self.root.after(self.time_between_moves, lambda: play_next_move(s, last_three, player, captures))\n",
    "        self.root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Socket-based communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Client suports the client connection and is responsible for defining encode and decode functions as well as receiving and treating information sent by the server\n",
    "\n",
    "To play with communication:\n",
    ">first: edit configurations \n",
    ">\n",
    ">start the server\n",
    ">\n",
    ">then call 2 seperatly mains()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client\n",
    "class Client:\n",
    "    def __init__(self, host=None, port = None):  # Defina PORT conforme necessário\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.ag=1\n",
    "\n",
    "    #ATAXX\n",
    "    #codificar\n",
    "    def stringify_move_ataxx(self, x, y, x2, y2):\n",
    "        return f\"MOVE {x},{y},{x2},{y2}\"\n",
    "    #descodificar\n",
    "    def decode_stringify_move_ataxx(self, move_message):\n",
    "        pattern = r\"MOVE (\\d+),(\\d+),(\\d+),(\\d+)\"\n",
    "        match = re.match(pattern, move_message)\n",
    "        if match:\n",
    "            x, y, x2, y2 = map(int, match.groups())\n",
    "            return x, y, x2, y2\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    #GO\n",
    "    def stringify_move_go(self, x, y):\n",
    "        return f\"MOVE {x},{y}\"\n",
    "    \n",
    "    def decode_stringify_move_go(self, move_message):\n",
    "        pattern = r\"MOVE (\\d+),(\\d+)\"\n",
    "        match = re.match(pattern, move_message)\n",
    "        if match:\n",
    "            x, y = map(int, match.groups())\n",
    "            return x, y\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    #conectar servividor\n",
    "    def connect_to_server(self):\n",
    "        self.client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        self.client_socket.connect((self.host, self.port))\n",
    "\n",
    "        response = self.client_socket.recv(1024).decode()\n",
    "        print(f\"Server ResponseINIT: {response}\")\n",
    "\n",
    "        #atualizar agente(de acordo com o servidor)\n",
    "        if \"1\" in response:\n",
    "            self.ag=1\n",
    "        else:\n",
    "            self.ag=2\n",
    "\n",
    "        #Obter informações do jogo(de acordo com o servidor) \n",
    "        Game = response[-4:] #ex: 'A6x6'\n",
    "        print(\"Playing:\", Game)\n",
    "        size = int(Game[1]) #ex: 6\n",
    "        jogo = Game[0]      #ex: 'A'\n",
    "\n",
    "        return size, jogo\n",
    "    \n",
    "    def get_ag(self):\n",
    "        return self.ag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for two agents to connect...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[43mstart_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m, in \u001b[0;36mstart_server\u001b[0;34m(host, port)\u001b[0m\n\u001b[1;32m      8\u001b[0m server_socket\u001b[38;5;241m.\u001b[39mlisten(\u001b[38;5;241m2\u001b[39m)                \n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaiting for two agents to connect...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m agent1, addr1 \u001b[38;5;241m=\u001b[39m \u001b[43mserver_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent 1 connected from\u001b[39m\u001b[38;5;124m\"\u001b[39m, addr1)\n\u001b[1;32m     13\u001b[0m bs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAG1 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mGame\u001b[38;5;241m.\u001b[39mencode()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/socket.py:293\u001b[0m, in \u001b[0;36msocket.accept\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccept\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    287\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"accept() -> (socket object, address info)\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m    Wait for an incoming connection.  Return a new socket\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    representing the connection, and the address of the client.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    For IP sockets, the address info is a pair (hostaddr, port).\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     fd, addr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accept\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m     sock \u001b[38;5;241m=\u001b[39m socket(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfamily, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto, fileno\u001b[38;5;241m=\u001b[39mfd)\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# Issue #7995: if no default timeout is set and the listening\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m# socket had a (non-zero) timeout, force the new socket in blocking\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# mode to override platform-specific socket flags inheritance.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# server\n",
    "Game = configurations['server_game']#\"A6x6\" \"A5x5\" \"A4x4\" \"G7x7\" \"G9x9\" \n",
    "\n",
    "def start_server(host=comunication['server_host'], port=comunication['port']):\n",
    "\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)   \n",
    "    server_socket.bind((host, port))\n",
    "    server_socket.listen(2)                \n",
    "    print(\"Waiting for two agents to connect...\")\n",
    "\n",
    "    agent1, addr1 = server_socket.accept()\n",
    "    print(\"Agent 1 connected from\", addr1)\n",
    "    bs=b'AG1 '+Game.encode()\n",
    "    agent1.sendall(bs)   #destinatário.sendall(mensagem)\n",
    "\n",
    "\n",
    "    agent2, addr2 = server_socket.accept()\n",
    "    print(\"Agent 2 connected from\", addr2)\n",
    "    bs=b'AG2 '+Game.encode()\n",
    "    agent2.sendall(bs)    \n",
    "\n",
    "\n",
    "    agents = [agent1, agent2]\n",
    "    current_agent = 0\n",
    "\n",
    "    jog=0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            #Recebe e descodifica a mensagem/JOGADA do 1º agente a entrar no server = agents[0]\n",
    "            #1024 bytes->max espaço de mensagem && .recv()->recebe mensagem\n",
    "            data = agents[current_agent].recv(1024).decode()\n",
    "            if not data:\n",
    "                print(\"server didn't receive data\")\n",
    "                break\n",
    "\n",
    "            # Process the move (example: \"MOVE X,Y\")\n",
    "            print(current_agent, \" -> \",data)\n",
    "            jog = jog+1\n",
    "            \n",
    "            # Send back a response: - VALID or INVALID to the sender, if the move is(n´t) valid\n",
    "            if is_valid_move(data):\n",
    "                #Se for válida, envia a jogada para o agente adeversário\n",
    "                agents[1-current_agent].sendall(data.encode())\n",
    "                print(\"server has sent\")\n",
    "            else:\n",
    "                print(\"invalid move\")\n",
    "            #agents[current_agent].sendall(b'INVALID')\n",
    "\n",
    "            # Switch to the other agent\n",
    "            current_agent = 1-current_agent  #mudar no jogo também?\n",
    "            time.sleep(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            traceback.print_exc()\n",
    "            break\n",
    "    \n",
    "    print(\"\\n-----------------\\nGAME END\\n-----------------\\n\")\n",
    "    time.sleep(1)\n",
    "    agent1.close()\n",
    "    agent2.close()\n",
    "    server_socket.close()\n",
    "\n",
    "def is_valid_move(move):\n",
    "    #we might not need this, so let's keep it true\n",
    "    return True \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid move\n",
      "invalid move\n",
      "invalid move\n",
      "cursor out of range\n",
      "PASS\n",
      "cursor out of range\n",
      "PASS\n",
      "cursor out of range\n",
      "PASS\n",
      "cursor out of range\n",
      "PASS\n",
      "cursor out of range\n",
      "PASS\n",
      "cursor out of range\n",
      "PASS\n",
      "cursor out of range\n",
      "PASS\n",
      "cursor out of range\n",
      "PASS\n",
      "____final_counting___\n",
      "\n",
      "Black captured: 0 White captured: 0\n",
      "\n",
      "Black points: 0 White points: 44.5\n",
      "\n",
      "________Winner_______:  white  by 44.5  difference\n",
      "[[-9 -9 -1 -9 -9 -1 -9]\n",
      " [-9 -9 -9 -9 -9 -9 -9]\n",
      " [-9 -9 -9 -9 -1 -9 -9]\n",
      " [-1 -9 -9 -1  1 -9 -9]\n",
      " [-9 -9 -9  1 -9 -9 -9]\n",
      " [-1 -9 -9 -9 -9 -9 -1]\n",
      " [-9 -9 -9 -9 -9 -9 -1]]\n",
      "Game Over - Winner: WHITE\n",
      "cursor out of range\n",
      "PASS\n",
      "____final_counting___\n",
      "\n",
      "Black captured: 0 White captured: 0\n",
      "\n",
      "Black points: 0 White points: 44.5\n",
      "\n",
      "________Winner_______:  white  by 44.5  difference\n",
      "[[-9 -9 -1 -9 -9 -1 -9]\n",
      " [-9 -9 -9 -9 -9 -9 -9]\n",
      " [-9 -9 -9 -9 -1 -9 -9]\n",
      " [-1 -9 -9 -1  1 -9 -9]\n",
      " [-9 -9 -9  1 -9 -9 -9]\n",
      " [-1 -9 -9 -9 -9 -9 -1]\n",
      " [-9 -9 -9 -9 -9 -9 -1]]\n",
      "Game Over - Winner: WHITE\n",
      "cursor out of range\n",
      "PASS\n",
      "____final_counting___\n",
      "\n",
      "Black captured: 0 White captured: 0\n",
      "\n",
      "Black points: 0 White points: 44.5\n",
      "\n",
      "________Winner_______:  white  by 44.5  difference\n",
      "[[-9 -9 -1 -9 -9 -1 -9]\n",
      " [-9 -9 -9 -9 -9 -9 -9]\n",
      " [-9 -9 -9 -9 -1 -9 -9]\n",
      " [-1 -9 -9 -1  1 -9 -9]\n",
      " [-9 -9 -9  1 -9 -9 -9]\n",
      " [-1 -9 -9 -9 -9 -9 -1]\n",
      " [-9 -9 -9 -9 -9 -9 -1]]\n",
      "Game Over - Winner: WHITE\n",
      "cursor out of range\n",
      "PASS\n",
      "____final_counting___\n",
      "\n",
      "Black captured: 0 White captured: 0\n",
      "\n",
      "Black points: 0 White points: 44.5\n",
      "\n",
      "________Winner_______:  white  by 44.5  difference\n",
      "[[-9 -9 -1 -9 -9 -1 -9]\n",
      " [-9 -9 -9 -9 -9 -9 -9]\n",
      " [-9 -9 -9 -9 -1 -9 -9]\n",
      " [-1 -9 -9 -1  1 -9 -9]\n",
      " [-9 -9 -9  1 -9 -9 -9]\n",
      " [-1 -9 -9 -9 -9 -9 -1]\n",
      " [-9 -9 -9 -9 -9 -9 -1]]\n",
      "Game Over - Winner: WHITE\n",
      "cursor out of range\n",
      "PASS\n",
      "____final_counting___\n",
      "\n",
      "Black captured: 0 White captured: 0\n",
      "\n",
      "Black points: 0 White points: 44.5\n",
      "\n",
      "________Winner_______:  white  by 44.5  difference\n",
      "[[-9 -9 -1 -9 -9 -1 -9]\n",
      " [-9 -9 -9 -9 -9 -9 -9]\n",
      " [-9 -9 -9 -9 -1 -9 -9]\n",
      " [-1 -9 -9 -1  1 -9 -9]\n",
      " [-9 -9 -9  1 -9 -9 -9]\n",
      " [-1 -9 -9 -9 -9 -9 -1]\n",
      " [-9 -9 -9 -9 -9 -9 -1]]\n",
      "Game Over - Winner: WHITE\n",
      "cursor out of range\n",
      "PASS\n",
      "____final_counting___\n",
      "\n",
      "Black captured: 0 White captured: 0\n",
      "\n",
      "Black points: 0 White points: 44.5\n",
      "\n",
      "________Winner_______:  white  by 44.5  difference\n",
      "[[-9 -9 -1 -9 -9 -1 -9]\n",
      " [-9 -9 -9 -9 -9 -9 -9]\n",
      " [-9 -9 -9 -9 -1 -9 -9]\n",
      " [-1 -9 -9 -1  1 -9 -9]\n",
      " [-9 -9 -9  1 -9 -9 -9]\n",
      " [-1 -9 -9 -9 -9 -9 -1]\n",
      " [-9 -9 -9 -9 -9 -9 -1]]\n",
      "Game Over - Winner: WHITE\n",
      "cursor out of range\n",
      "PASS\n",
      "____final_counting___\n",
      "\n",
      "Black captured: 0 White captured: 0\n",
      "\n",
      "Black points: 0 White points: 44.5\n",
      "\n",
      "________Winner_______:  white  by 44.5  difference\n",
      "[[-9 -9 -1 -9 -9 -1 -9]\n",
      " [-9 -9 -9 -9 -9 -9 -9]\n",
      " [-9 -9 -9 -9 -1 -9 -9]\n",
      " [-1 -9 -9 -1  1 -9 -9]\n",
      " [-9 -9 -9  1 -9 -9 -9]\n",
      " [-1 -9 -9 -9 -9 -9 -1]\n",
      " [-9 -9 -9 -9 -9 -9 -1]]\n",
      "Game Over - Winner: WHITE\n",
      "cursor out of range\n",
      "PASS\n",
      "____final_counting___\n",
      "\n",
      "Black captured: 0 White captured: 0\n",
      "\n",
      "Black points: 0 White points: 44.5\n",
      "\n",
      "________Winner_______:  white  by 44.5  difference\n",
      "[[-9 -9 -1 -9 -9 -1 -9]\n",
      " [-9 -9 -9 -9 -9 -9 -9]\n",
      " [-9 -9 -9 -9 -1 -9 -9]\n",
      " [-1 -9 -9 -1  1 -9 -9]\n",
      " [-9 -9 -9  1 -9 -9 -9]\n",
      " [-1 -9 -9 -9 -9 -9 -1]\n",
      " [-9 -9 -9 -9 -9 -9 -1]]\n",
      "Game Over - Winner: WHITE\n",
      "cursor out of range\n",
      "PASS\n",
      "____final_counting___\n",
      "\n",
      "Black captured: 0 White captured: 0\n",
      "\n",
      "Black points: 0 White points: 44.5\n",
      "\n",
      "________Winner_______:  white  by 44.5  difference\n",
      "[[-9 -9 -1 -9 -9 -1 -9]\n",
      " [-9 -9 -9 -9 -9 -9 -9]\n",
      " [-9 -9 -9 -9 -1 -9 -9]\n",
      " [-1 -9 -9 -1  1 -9 -9]\n",
      " [-9 -9 -9  1 -9 -9 -9]\n",
      " [-1 -9 -9 -9 -9 -9 -1]\n",
      " [-9 -9 -9 -9 -9 -9 -1]]\n",
      "Game Over - Winner: WHITE\n",
      "cursor out of range\n",
      "PASS\n",
      "____final_counting___\n",
      "\n",
      "Black captured: 0 White captured: 0\n",
      "\n",
      "Black points: 0 White points: 44.5\n",
      "\n",
      "________Winner_______:  white  by 44.5  difference\n",
      "[[-9 -9 -1 -9 -9 -1 -9]\n",
      " [-9 -9 -9 -9 -9 -9 -9]\n",
      " [-9 -9 -9 -9 -1 -9 -9]\n",
      " [-1 -9 -9 -1  1 -9 -9]\n",
      " [-9 -9 -9  1 -9 -9 -9]\n",
      " [-1 -9 -9 -9 -9 -9 -1]\n",
      " [-9 -9 -9 -9 -9 -9 -1]]\n",
      "Game Over - Winner: WHITE\n",
      "cursor out of range\n",
      "PASS\n",
      "____final_counting___\n",
      "\n",
      "Black captured: 0 White captured: 0\n",
      "\n",
      "Black points: 0 White points: 44.5\n",
      "\n",
      "________Winner_______:  white  by 44.5  difference\n",
      "[[-9 -9 -1 -9 -9 -1 -9]\n",
      " [-9 -9 -9 -9 -9 -9 -9]\n",
      " [-9 -9 -9 -9 -1 -9 -9]\n",
      " [-1 -9 -9 -1  1 -9 -9]\n",
      " [-9 -9 -9  1 -9 -9 -9]\n",
      " [-1 -9 -9 -9 -9 -9 -1]\n",
      " [-9 -9 -9 -9 -9 -9 -1]]\n",
      "Game Over - Winner: WHITE\n",
      "cursor out of range\n",
      "PASS\n",
      "____final_counting___\n",
      "\n",
      "Black captured: 0 White captured: 0\n",
      "\n",
      "Black points: 0 White points: 44.5\n",
      "\n",
      "________Winner_______:  white  by 44.5  difference\n",
      "[[-9 -9 -1 -9 -9 -1 -9]\n",
      " [-9 -9 -9 -9 -9 -9 -9]\n",
      " [-9 -9 -9 -9 -1 -9 -9]\n",
      " [-1 -9 -9 -1  1 -9 -9]\n",
      " [-9 -9 -9  1 -9 -9 -9]\n",
      " [-1 -9 -9 -9 -9 -9 -1]\n",
      " [-9 -9 -9 -9 -9 -9 -1]]\n",
      "Game Over - Winner: WHITE\n",
      "cursor out of range\n",
      "PASS\n",
      "____final_counting___\n",
      "\n",
      "Black captured: 0 White captured: 0\n",
      "\n",
      "Black points: 0 White points: 44.5\n",
      "\n",
      "________Winner_______:  white  by 44.5  difference\n",
      "[[-9 -9 -1 -9 -9 -1 -9]\n",
      " [-9 -9 -9 -9 -9 -9 -9]\n",
      " [-9 -9 -9 -9 -1 -9 -9]\n",
      " [-1 -9 -9 -1  1 -9 -9]\n",
      " [-9 -9 -9  1 -9 -9 -9]\n",
      " [-1 -9 -9 -9 -9 -9 -1]\n",
      " [-9 -9 -9 -9 -9 -9 -1]]\n",
      "Game Over - Winner: WHITE\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    #comunication\n",
    "    if configurations['comunication']:\n",
    "        player = Client(host = comunication['client_host'], port = comunication['port'])\n",
    "        size, jogo = player.connect_to_server()\n",
    "        ag = player.get_ag()\n",
    "        _game_mode = game_mode['agent_vs_agent']\n",
    "    #no comunicatin\n",
    "    else:\n",
    "        size = configurations['size']\n",
    "        jogo = configurations['jogo']\n",
    "        _game_mode = configurations['game_mode']\n",
    "        player = None\n",
    "        ag = None\n",
    "\n",
    "    if jogo == 'G':\n",
    "        game = Go(size)\n",
    "        #7 ou 9?\n",
    "        initial_state = board7['board'] if size == 7 else board9['board']\n",
    "        time_between_moves = configurations['time_between_moves']\n",
    "\n",
    "        interfaceGo(size, game, initial_state, _game_mode, time_between_moves, client = player, ag = ag)\n",
    "\n",
    "    elif jogo == 'A':\n",
    "        game = Ataxx(size)\n",
    "        #6 5 ou 4?\n",
    "        initial_state = board4['board'] if size == 4 else (board6['board'] if size == 6 else board5['board'])\n",
    "        time_between_moves = configurations['time_between_moves']\n",
    "\n",
    "        interfaceAtaxx(size, game, initial_state, _game_mode, time_between_moves, client=player, ag=ag)\n",
    "       \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's to the algotithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                Alpha Zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  For Ataxx and Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import what's needed\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import asyncio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, game, args, state, parent=None, action_taken=None, prior=0, visit_count = 0):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action_taken = action_taken\n",
    "        self.prior = prior \n",
    "\n",
    "        self.children = []\n",
    "        self.visit_count = visit_count\n",
    "        self.value_sum = 0\n",
    "    \n",
    "    def get_last_nine(self):\n",
    "        #for thre fold repetition rule\n",
    "        return self.last_nine\n",
    "    \n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def select(self):\n",
    "        best_child = None\n",
    "        best_ucb = -np.inf \n",
    "        #selection by higher UCB\n",
    "        for child in self.children:\n",
    "            ucb = self.get_ucb(child)\n",
    "            if ucb > best_ucb:\n",
    "                best_child = child\n",
    "                best_ucb = ucb\n",
    "        \n",
    "        return best_child\n",
    "   \n",
    "    def get_ucb(self, child):\n",
    "        if child.visit_count == 0:\n",
    "            q_value = 0\n",
    "        else:\n",
    "            q_value = 1 - ((child.value_sum/child.visit_count)+1) / 2   \n",
    "        return q_value + self.args['C'] * (math.sqrt(self.visit_count)/(child.visit_count+1)) * child.prior\n",
    "   \n",
    "    def expand(self, policy):\n",
    "        #we exapnd all possible in one expansion\n",
    "        child = None\n",
    "        for action, prob in policy.items():\n",
    "            if prob > 0:\n",
    "                child_state = self.state.copy()\n",
    "                child_state = self.game.play_move(action, child_state,1)\n",
    "                child_state = self.game.change_perspective(child_state)\n",
    "\n",
    "                child = Node(self.game, self.args, child_state, self, action, prob)\n",
    "                self.children.append(child)\n",
    "  \n",
    "    def backpropagate(self, value):\n",
    "        self.value_sum += value\n",
    "        self.visit_count += 1\n",
    "        value = self.game.get_opponent_value(value)\n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(value)\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game, args, model):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "    \n",
    "    @torch.no_grad() \n",
    "    def search(self, state):\n",
    "        root = Node(self.game, self.args, state, visit_count=1) \n",
    "        \n",
    "        full_action_space_dict = self.game.action_dict()  \n",
    "\n",
    "        # Add noise to root node\n",
    "        policy, _ = self.model(\n",
    "            torch.tensor(self.game.get_encoded_state(state)).unsqueeze(0)\n",
    "        )\n",
    "        policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
    "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
    "            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size)\n",
    "\n",
    "        policy /= np.sum(policy)           \n",
    "\n",
    "        for i in range(len(policy)):\n",
    "            if policy[i] > 0:\n",
    "                play_key_at_index = list(full_action_space_dict.keys())[i]   \n",
    "                if self.game.verify_move(play_key_at_index, state, 1):    \n",
    "                    full_action_space_dict[play_key_at_index] = policy[i]\n",
    "                else:\n",
    "                    full_action_space_dict[play_key_at_index] = 0.0\n",
    "            else:\n",
    "                play_at_index = list(full_action_space_dict.keys())[i]    \n",
    "                full_action_space_dict[play_at_index] = 0.0\n",
    "\n",
    "        root.expand(full_action_space_dict)\n",
    "\n",
    "        for search in range(self.args['num_searches']):\n",
    "            node = root\n",
    "\n",
    "            # Selection \n",
    "            while node.is_fully_expanded():\n",
    "                node = node.select()\n",
    "\n",
    "            # Check if the node we selected is terminal\n",
    "            value, is_terminal = self.game.get_value_and_terminated(node.state, 1) \n",
    "            value = self.game.get_opponent_value(value)  \n",
    "  \n",
    "            # Expansion\n",
    "            if not is_terminal:\n",
    "                policy, value = self.model(\n",
    "                    torch.tensor(self.game.get_encoded_state(node.state)).unsqueeze(0)  \n",
    "                )\n",
    "                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy() \n",
    "                # Normalize policy\n",
    "                policy /= np.sum(policy) \n",
    "                # Mask valide plays\n",
    "                for i in range(len(policy)):\n",
    "                    if policy[i] > 0:\n",
    "                        play_key_at_index = list(full_action_space_dict.keys())[i]   \n",
    "                        if self.game.verify_move(play_key_at_index, node.state, 1):    \n",
    "                            full_action_space_dict[play_key_at_index] = policy[i]\n",
    "                        else:\n",
    "                            full_action_space_dict[play_key_at_index] = 0.0\n",
    "                    else:\n",
    "                        play_at_index = list(full_action_space_dict.keys())[i]    \n",
    "                        full_action_space_dict[play_at_index] = 0.0\n",
    "\n",
    "                value = value.item() \n",
    "         \n",
    "                node.expand(full_action_space_dict)\n",
    "       \n",
    "            node.backpropagate(value) \n",
    "\n",
    "        actions_dict = self.game.action_dict()\n",
    "        for child in root.children:\n",
    "            action = child.action_taken\n",
    "            actions_dict[action] = child.visit_count\n",
    "        action_probs = np.array(list(actions_dict.values()))\n",
    "        action_probs /= np.sum(action_probs)\n",
    "        return action_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    #Res Blocks are better dealing with gradient vanishing on deeper networks\n",
    "    def __init__(self, game, num_resBlocks, num_hidden):\n",
    "        super().__init__()\n",
    "        self.startBlock = nn.Sequential(\n",
    "            nn.Conv2d(3, num_hidden, kernel_size=3, padding=1),     \n",
    "            nn.BatchNorm2d(num_hidden),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.backBone = nn.ModuleList(\n",
    "            [ResBlock(num_hidden, 3) for i in range(num_resBlocks)]\n",
    "        )\n",
    "\n",
    "        self.policyHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, 32, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * game.size * game.size, game.action_size)  \n",
    "        )                                                 \n",
    "        self.valueHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, 3, kernel_size=3, padding=1),  \n",
    "            nn.BatchNorm2d(3), \n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * game.size * game.size, 1),  \n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.startBlock(x)\n",
    "        for resBlock in self.backBone:\n",
    "            x = resBlock(x)\n",
    "        policy = self.policyHead(x)\n",
    "        value = self.valueHead(x)\n",
    "        return policy, value\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_hidden, board_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)  \n",
    "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
    "        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1) \n",
    "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaZero:\n",
    "    def __init__(self, model, optimizer, game, args):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.mcts = MCTS(game, args, model)\n",
    "        \n",
    "    def selfPlay(self):\n",
    "        memory = []\n",
    "        player = 1\n",
    "        state = self.game.make_s0()\n",
    "\n",
    "        \n",
    "        while True:          \n",
    "            if (player == -1):\n",
    "                neutral_state = self.game.change_perspective(state)\n",
    "            else:\n",
    "                neutral_state = state\n",
    "\n",
    "            action_probs = self.mcts.search(neutral_state)\n",
    "\n",
    "            memory.append((neutral_state, action_probs, player)) \n",
    "            \n",
    "            temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n",
    "            temperature_action_probs /= np.sum[temperature_action_probs]\n",
    "            all_actions = self.game.get_all_actions()\n",
    "            action_index = np.random.choice(self.game.action_size, p=temperature_action_probs)\n",
    "            action = all_actions[action_index]\n",
    "      \n",
    "            state = self.game.play_move(action, state, player)\n",
    "         \n",
    "            value, is_terminal = self.game.get_value_and_terminated(state, player)\n",
    "            \n",
    "            if is_terminal or self.game.is_stuck(state, -player):\n",
    "                returnMemory = []\n",
    "                for hist_neutral_state, hist_action_probs, hist_player in memory:\n",
    "                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
    "                    returnMemory.append((\n",
    "                        self.game.get_encoded_state(hist_neutral_state),\n",
    "                        hist_action_probs,\n",
    "                        hist_outcome\n",
    "                    ))\n",
    "                return returnMemory\n",
    "            \n",
    "            player = self.game.change_turn(player)\n",
    "                \n",
    "    def train(self, memory):\n",
    "        random.shuffle(memory)\n",
    "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
    "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
    "            state, policy_targets, value_targets = zip(*sample)\n",
    "            \n",
    "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
    "            \n",
    "            state = torch.tensor(state, dtype=torch.float32)\n",
    "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32)\n",
    "            value_targets = torch.tensor(value_targets, dtype=torch.float32)\n",
    "            \n",
    "            out_policy, out_value = self.model(state)\n",
    "            \n",
    "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
    "            value_loss = F.mse_loss(out_value, value_targets)\n",
    "            loss = policy_loss + value_loss\n",
    "            \n",
    "            self.optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            self.optimizer.step() \n",
    "    \n",
    "    def learn(self):\n",
    "        for iteration in range(self.args['num_iterations']):\n",
    "            memory = []\n",
    "            \n",
    "            self.model.eval()\n",
    "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations']):\n",
    "                memory += self.selfPlay()\n",
    "                \n",
    "            self.model.train()\n",
    "            for epoch in trange(self.args['num_epochs']):\n",
    "                self.train(memory)\n",
    "            \n",
    "            torch.save(self.model.state_dict(), f\"model_{iteration}.pt\")\n",
    "            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AlphaZero Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSParallel:\n",
    "    def __init__(self, game, args, model):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "    \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def search(self, states, spGames):\n",
    "        full_action_space_dict = self.game.action_dict()  \n",
    "\n",
    "        # Add noise to root node\n",
    "        policy, _ = self.model(\n",
    "            torch.tensor(self.game.get_encoded_state(states))\n",
    "        )\n",
    "        policy = torch.softmax(policy, axis=1).cpu().numpy()\n",
    "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
    "            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size, size=policy.shape[0])\n",
    "\n",
    "        for j, spg in enumerate(spGames):\n",
    "            spg_policy = policy[j]\n",
    "            # Normalize Policys\n",
    "            spg_policy /= np.sum(spg_policy)\n",
    "            # Mask valide moves\n",
    "            for i in range(len(spg_policy)):\n",
    "                if spg_policy[i] > 0:\n",
    "                    play_key_at_index = list(full_action_space_dict.keys())[i]   \n",
    "                    if self.game.verify_move(play_key_at_index, states[j], 1):    \n",
    "                        full_action_space_dict[play_key_at_index] = spg_policy[i]\n",
    "                    else:\n",
    "                        full_action_space_dict[play_key_at_index] = 0.0\n",
    "                else:\n",
    "                    play_at_index = list(full_action_space_dict.keys())[i]    \n",
    "                    full_action_space_dict[play_at_index] = 0.0\n",
    "\n",
    "            spg.root = Node(self.game, self.args, states[j], visit_count=1)\n",
    "            spg.root.expand(full_action_space_dict) \n",
    "\n",
    "\n",
    "        for search in range(self.args['num_searches']):\n",
    "            for spg in spGames:\n",
    "                spg.node = None\n",
    "                node = spg.root\n",
    "\n",
    "                while node.is_fully_expanded():\n",
    "                    node = node.select()\n",
    "            \n",
    "                value, is_terminal = self.game.get_value_and_terminated(node.state, 1) \n",
    "                value = self.game.get_opponent_value(value)\n",
    "\n",
    "                if is_terminal:\n",
    "                    node.backpropagate(value)\n",
    "                else:\n",
    "                    spg.node = node\n",
    "                \n",
    "            expandable_spGames = [mappingIdx for mappingIdx in range(len(spGames)) if spGames[mappingIdx].node is not None]\n",
    "\n",
    "            if (len(expandable_spGames)) > 0:\n",
    "                states = np.stack([spGames[mappingIdx].node.state for mappingIdx in expandable_spGames])\n",
    "                policy, value = self.model(\n",
    "                    torch.tensor(self.game.get_encoded_state(states)) \n",
    "                )\n",
    "                policy = torch.softmax(policy, axis=1).cpu().numpy()\n",
    "                value = value.cpu().numpy()\n",
    "\n",
    "            for j, mappingIdx in enumerate(expandable_spGames):\n",
    "                node = spGames[mappingIdx].node\n",
    "                spg_policy, spg_value = policy[j], value[j]\n",
    "                spg_policy /= np.sum(spg_policy) \n",
    "                for i in range(len(spg_policy)):\n",
    "                    if spg_policy[i] > 0:\n",
    "                        play_key_at_index = list(full_action_space_dict.keys())[i]   \n",
    "                        if self.game.verify_move(play_key_at_index, node.state, 1):    \n",
    "                            full_action_space_dict[play_key_at_index] = spg_policy[i]\n",
    "                        else:\n",
    "                            full_action_space_dict[play_key_at_index] = 0.0\n",
    "                    else:\n",
    "                        play_at_index = list(full_action_space_dict.keys())[i]    \n",
    "                        full_action_space_dict[play_at_index] = 0.0\n",
    "\n",
    "                node.expand(full_action_space_dict)\n",
    "                node.backpropagate(spg_value) \n",
    "\n",
    "        \n",
    "class AlphaZeroParallel:\n",
    "    def __init__(self, model, optimizer, game, args):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.mcts = MCTSParallel(game, args, model)\n",
    "        \n",
    "    def selfPlay(self):\n",
    "        return_memory = []\n",
    "        player = 1\n",
    "        spGames = [SPG(self.game) for spg in range(self.args['num_parallel_games'])]\n",
    "\n",
    "        while len(spGames) > 0:\n",
    "            states = np.stack([spg.state for spg in spGames])\n",
    "\n",
    "            if (player == -1):\n",
    "                neutral_states = self.game.change_perspective(states)\n",
    "            else:\n",
    "                neutral_states = states\n",
    "            \n",
    "            self.mcts.search(neutral_states, spGames)\n",
    "            \n",
    "            for i in range(len(spGames))[::-1]:\n",
    "                spg = spGames[i]\n",
    "\n",
    "                actions_dict = self.game.action_dict()\n",
    "                for child in spg.root.children:\n",
    "                    actions_dict[child.action_taken] = child.visit_count\n",
    "                action_probs = np.array(list(actions_dict.values()))\n",
    "                action_probs /= np.sum(action_probs)\n",
    "\n",
    "                spg.memory.append((spg.root.state, action_probs, player)) \n",
    "\n",
    "                temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n",
    "                temperature_action_probs /= np.sum(temperature_action_probs)\n",
    "                all_actions = self.game.get_all_actions()\n",
    "                action_index = np.random.choice(self.game.action_size, p=temperature_action_probs)\n",
    "                action = all_actions[action_index]\n",
    "\n",
    "                spg.state = self.game.play_move(action, spg.state, player)\n",
    "            \n",
    "                value, is_terminal = self.game.get_value_and_terminated(spg.state, player)\n",
    "            \n",
    "                if is_terminal or self.game.is_stuck(spg.state, -player):\n",
    "                    for hist_neutral_state, hist_action_probs, hist_player in spg.memory:\n",
    "                        hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
    "                        return_memory.append((\n",
    "                            self.game.get_encoded_state(hist_neutral_state),\n",
    "                            hist_action_probs,\n",
    "                            hist_outcome\n",
    "                        ))\n",
    "                    del spGames[i]\n",
    "            \n",
    "            player = self.game.change_turn(player)\n",
    "        \n",
    "        return return_memory\n",
    "                \n",
    "    def train(self, memory):\n",
    "        random.shuffle(memory)\n",
    "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
    "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
    "            state, policy_targets, value_targets = zip(*sample)\n",
    "            \n",
    "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
    "            \n",
    "            state = torch.tensor(state, dtype=torch.float32)\n",
    "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32)\n",
    "            value_targets = torch.tensor(value_targets, dtype=torch.float32)\n",
    "            \n",
    "            out_policy, out_value = self.model(state)\n",
    "            \n",
    "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
    "            value_loss = F.mse_loss(out_value, value_targets)\n",
    "            loss = policy_loss + value_loss\n",
    "            \n",
    "            self.optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            self.optimizer.step() \n",
    "    \n",
    "    def learn(self):\n",
    "        for iteration in range(self.args['num_iterations']):\n",
    "            memory = []\n",
    "            \n",
    "            self.model.eval()\n",
    "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations'] // self.args['num_parallel_games']):\n",
    "                memory += self.selfPlay()\n",
    "                \n",
    "            self.model.train()\n",
    "            for epoch in trange(self.args['num_epochs']):\n",
    "                self.train(memory)\n",
    "            \n",
    "            torch.save(self.model.state_dict(), f\"model_{iteration}.pt\")\n",
    "            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}.pt\")\n",
    "\n",
    "\n",
    "class SPG:\n",
    "    def __init__(self, game):\n",
    "        self.state = game.make_s0()\n",
    "        self.memory = []\n",
    "        self.root = None\n",
    "        self.node = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this are test values\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 5,#60,\n",
    "    'num_iterations': 3,\n",
    "    'num_selfPlay_iterations': 20, #500,\n",
    "    'num_parallel_games': 10, #100,\n",
    "    'num_epochs': 2, #4\n",
    "    'batch_size': 32, #64\n",
    "    'temperature': 1.25, \n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2534286486174e9fa6023fe01aca18b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcd4137a3e24ff391a59247af5ebaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a49fcab78849e09904543c3d05816e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ca05790c71497abdb22939458ade7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6a6ea3e7e040aa9e05e32201bfc0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f861cf784a473cacbb0d69ea5626a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ataxx = Ataxx(4)\n",
    "\n",
    "model = ResNet(ataxx, 10, 256)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay = 0.0001)\n",
    "\n",
    "alphaZero = AlphaZeroParallel(model, optimizer, ataxx, args)\n",
    "alphaZero.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
